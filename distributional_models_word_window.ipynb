{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Distributional Semantics Model: Narrow Word-Window (-2,+2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### A. Data-Loading Facilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "os.chdir(\"/Users/jacobsw/Desktop/IMPLEMENTATION_CAMP/CODE/BASIC_TOPICS/DISTRIBUTIONAL_SEMANTICS/ASSIGNMENT_03\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "stopwords = stopwords.words('english')\n",
    "from collections import defaultdict, Counter\n",
    "from functools import partial\n",
    "from itertools import permutations, product\n",
    "punctuation = '!\"#$%&\\'()*+,-/:;<=>?@[\\\\]^_`{|}~'\n",
    "from operator import itemgetter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def load_wiki(cutoffFreq=20):\n",
    "    \n",
    "    print \"... extracting data\"\n",
    "    with open('wikicorpus.txt','rb') as f:\n",
    "        raw = f.readlines()\n",
    "    raw = [sent[4:].split() for sent in raw if sent.startswith('<c>')] \n",
    "        # sent[4:]: get rid of initial <c>.\n",
    "        # extract sentences; split sentences into word complexes.\n",
    "    raw = [[map(partial(str.split, word), '|') for word in sent] for sent in raw] \n",
    "        # split word complexes into words.\n",
    "    \n",
    "    print \"... cleaning data\"\n",
    "    tagged_sents = [[(word[0][1].lower(),word[0][2]) for word in sent if len(word[0])>1 \n",
    "                      and word[0][1].lower() not in stopwords\n",
    "                      and word[0][1] not in punctuation] for sent in raw]\n",
    "    \n",
    "    print \"... getting top-%d frequent context words and top-50 frequent nouns\" % cutoffFreq\n",
    "    all_tokens = [word for tagged_sent in tagged_sents for word,tag in tagged_sent]\n",
    "        # type: list of words.\n",
    "    context_fdist = Counter(all_tokens)\n",
    "    context_vocab = list({word for word,freq in context_fdist.iteritems() if freq>=cutoffFreq})\n",
    "    n_tokens = [word for tagged_sent in tagged_sents for word,tag in tagged_sent if tag.startswith('N')]\n",
    "    n_fdist = Counter(n_tokens)\n",
    "    n_vocab = list({word for word,freq in n_fdist.iteritems() if freq>=50})\n",
    "    \n",
    "    sents = [[word for word,tag in tagged_sent if word in context_vocab] for tagged_sent in tagged_sents]\n",
    "    \n",
    "    return (n_vocab, context_vocab, sents)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "... extracting data\n",
      "... cleaning data\n",
      "... getting top-20 frequent context words and top-50 frequent nouns\n",
      "CPU times: user 19min 23s, sys: 9.23 s, total: 19min 32s\n",
      "Wall time: 19min 30s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "n_vocab, context_vocab, sents = load_wiki()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import cPickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "cleaned_data_path = '/Users/jacobsw/Desktop/IMPLEMENTATION_CAMP/CODE/BASIC_TOPICS/DISTRIBUTIONAL_SEMANTICS/CODE/CLEANED_DATA/'\n",
    "# cPickle.dump((n_vocab,context_vocab,sents), open(cleaned_data_path+'cleaned_wiki.p', 'wb')) \n",
    "n_vocab, context_vocab, sents = cPickle.load(open(cleaned_data_path+'cleaned_wiki.p', 'rb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### B1. Analyzer: Cooccurrence Matrix Based"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### A. Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# SIMILARITY MEASURES\n",
    "def cosine(w2w):\n",
    "    w2w_norm = w2w / np.apply_along_axis(lambda r: np.sqrt(np.dot(r,r))\n",
    "                               , 1, w2w)[:,np.newaxis]\n",
    "    return np.dot(w2w_norm, w2w_norm.T)\n",
    "    \n",
    "def ppmi(w2w):\n",
    "    rowSums, colSums, totalSums = w2w.sum(axis=1), w2w.sum(axis=0), w2w.sum()\n",
    "    pwi, pwj, ppmiMatrix = rowSums/totalSums, colSums/totalSums, w2w/totalSums\n",
    "    ppmiMatrix /= pwi[:,np.newaxis] # * 1/pwi by row.\n",
    "    ppmiMatrix /= pwj # * 1/pwj by col.\n",
    "    ppmiMatrix = np.nan_to_num(np.log(ppmiMatrix)) # compute pmi.\n",
    "    ppmiMatrix = np.maximum(ppmiMatrix, 0) # compute ppmi.\n",
    "    return ppmiMatrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class SimpleDistSem:\n",
    "    \n",
    "    def __init__(self, target_vocab, context_vocab, sents):\n",
    "        self.sents = sents \n",
    "            # a list of sents considered in the corpus.\n",
    "            #  in this case, words in context_vocab.\n",
    "        self.vocab = target_vocab\n",
    "        self.context = context_vocab\n",
    "        self.t2i = {t:i for i,t in enumerate(self.vocab)}\n",
    "        self.c2i = {word:i for i,word in enumerate(self.context)}\n",
    "        self.algos = {'ppmi':ppmi, 'cosine':cosine}\n",
    "    \n",
    "    def build_t2c_matrix(self, win_size):\n",
    "        \n",
    "        print \"... counting words\"\n",
    "        cooccurrenceDict = defaultdict(int)\n",
    "        for sent in self.sents:\n",
    "            for i,target in enumerate(sent):\n",
    "                contexts = sent[max(0,i-win_size):i] + \\\n",
    "                           sent[min(i+1,len(sent)):min(i+1+win_size,len(sent))]\n",
    "                for context in contexts:\n",
    "                    cooccurrenceDict[(target,context)] += 1\n",
    "        \n",
    "        print \"... building cooccurrence matrix\"\n",
    "        self.t2c = np.zeros((len(self.vocab),len(self.context)))\n",
    "        for target in self.vocab:\n",
    "            for context in self.context:\n",
    "                self.t2c[self.t2i[target]][self.c2i[context]] = cooccurrenceDict[(target,context)]\n",
    "    \n",
    "    def build_similarity_matrix(self, similarity='ppmi'):\n",
    "        self.sim_algo = similarity\n",
    "        self.simMatrix = self.algos[similarity](self.t2c)\n",
    "    \n",
    "    def k_most_similar(self, words, k=20):\n",
    "        assert len(words)==len(filter(lambda w:1 if w in self.vocab else 0, words))\n",
    "        w2sim = {}\n",
    "        for word in words:\n",
    "            simList = self.simMatrix[self.t2i[word]]\n",
    "            if self.sim_algo=='ppmi':\n",
    "                w2sim[word] = map(lambda idx:(self.context[idx],\n",
    "                                              self.simMatrix[self.t2i[word]][idx]),\n",
    "                                  np.argsort(simList)[::-1][1:k+1])\n",
    "            else:\n",
    "                w2sim[word] = map(lambda idx:(self.vocab[idx],\n",
    "                                              self.simMatrix[self.t2i[word]][idx]),\n",
    "                                  np.argsort(simList)[::-1][1:k+1])                \n",
    "            # [1:k+1]: skip self-similarty.\n",
    "        return w2sim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 5.41 ms, sys: 3.11 ms, total: 8.53 ms\n",
      "Wall time: 6.59 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "ds = SimpleDistSem(n_vocab,context_vocab,sents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "... counting words\n",
      "... building cooccurrence matrix\n",
      "CPU times: user 4min 41s, sys: 1min 23s, total: 6min 4s\n",
      "Wall time: 6min 43s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "ds.build_t2c_matrix(win_size=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# model_path = '/Users/jacobsw/Desktop/IMPLEMENTATION_CAMP/CODE/BASIC_TOPICS/DISTRIBUTIONAL_SEMANTICS/CODE/MODELS/'\n",
    "# cPickle.dump(ds.t2c, open(model_path+'t2c_matrix.p', 'wb')) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### b. Evaluator: K-Frequent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 4.13 s, sys: 1.97 s, total: 6.1 s\n",
      "Wall time: 6.19 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "ds.build_similarity_matrix('ppmi')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 6.73 ms, sys: 2.6 ms, total: 9.33 ms\n",
      "Wall time: 10.8 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "words = ['car','bus','hospital','hotel','gun','bomb','horse','fox','table','bowl','guitar','piano']\n",
    "w2sim = ds.k_most_similar(words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('trailer', 5.1857276736791285),\n",
       " ('dkw', 5.1522797396115889),\n",
       " ('racer', 5.0344967039552051),\n",
       " ('armored', 4.9336576730162252),\n",
       " ('touring', 4.8580402666136484),\n",
       " ('bugatti', 4.8195739857858522),\n",
       " ('f1', 4.8195739857858522),\n",
       " ('vintage', 4.7870885306413644),\n",
       " ('marque', 4.7468146315034243),\n",
       " ('dine', 4.7208391451001637),\n",
       " ('racing', 4.7208391451001637),\n",
       " ('dining', 4.6955213371158742),\n",
       " ('cab', 4.670828724525502),\n",
       " ('brabham', 4.668613884195949),\n",
       " ('bentley', 4.6399514859610633),\n",
       " ('rolls-royce', 4.6116398531351717),\n",
       " ('luxurious', 4.5557593947407149),\n",
       " ('cable', 4.5300068986383),\n",
       " ('dat', 4.4723777858016645),\n",
       " ('nissan', 4.4565044366453739)]"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w2sim['car']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 59.6 s, sys: 579 ms, total: 1min\n",
      "Wall time: 9.03 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "ds.build_similarity_matrix('cosine')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 7.67 ms, sys: 2.3 ms, total: 9.97 ms\n",
      "Wall time: 13.8 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "words = ['car','bus','hospital','hotel','gun','bomb','horse','fox','table','bowl','guitar','piano']\n",
    "w2sim = ds.k_most_similar(words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('piano', 0.99999999999999933),\n",
       " ('violin', 0.76368146451719332),\n",
       " ('concerto', 0.71305548309401001),\n",
       " ('music', 0.70673316507963324),\n",
       " ('piece', 0.70201611051983126),\n",
       " ('guitar', 0.70086723926027006),\n",
       " ('style', 0.70012528258655737),\n",
       " ('instrument', 0.69917583835334074),\n",
       " ('sonata', 0.69868311876137723),\n",
       " ('string', 0.69210834145722122),\n",
       " ('cello', 0.68807570933281426),\n",
       " ('game', 0.68766966846985655),\n",
       " ('work', 0.68287314047592962),\n",
       " ('composition', 0.68272213494477585),\n",
       " ('sound', 0.6772838583009273),\n",
       " ('performance', 0.67462257053125896),\n",
       " ('time', 0.67272691451210609),\n",
       " ('history', 0.67025843987813449),\n",
       " ('poetry', 0.66947592455636917),\n",
       " ('banjo', 0.66941867870707361)]"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w2sim['piano']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### c. Evaluator: BLESS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def bless_evaluator(simMatrix, indexers):\n",
    "    t2i,c2i = indexers\n",
    "    path = '/Users/jacobsw/Desktop/IMPLEMENTATION_CAMP/CODE/BASIC_TOPICS/DISTRIBUTIONAL_SEMANTICS/ASSIGNMENT_03/BLESS_part.txt'\n",
    "    with open(path,'rb') as f:\n",
    "        bless = f.readlines()\n",
    "    bless = [line.split('\\t') for line in bless] # split into (concept, _, relation, relatum).\n",
    "    crPairs = [(c.split('-')[0],r.split('-')[0],rel) for c,_,rel,r in bless]\n",
    "    posPairs = [(c,r) for c,r,rel in crPairs if rel=='hyper']\n",
    "    negPairs = [(c,r) for c,r,rel in crPairs if rel=='mero']\n",
    "    \n",
    "    return [map(lambda (c,r):(c,r,simMatrix[t2i[c]][c2i[r]]), posPairs),\n",
    "            map(lambda (c,r):(c,r,simMatrix[t2i[c]][c2i[r]]), negPairs)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### PPMI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 4.19 s, sys: 1.69 s, total: 5.88 s\n",
      "Wall time: 5.92 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "ds.build_similarity_matrix('ppmi')\n",
    "posEval, negEval = bless_evaluator(ds.simMatrix, indexers=[ds.t2i,ds.c2i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Examples of Evaluation on Positive Relations (PPMI): \n",
      "[('helicopter', 'vehicle', 0.0), ('pistol', 'object', 0.0), ('coyote', 'beast', 0.0), ('violin', 'object', 0.0), ('frog', 'creature', 0.0)]\n",
      "Average PPMI:  1.30368679677\n"
     ]
    }
   ],
   "source": [
    "print \"Examples of Evaluation on Positive Relations (PPMI): \"\n",
    "print random.sample(posEval, 5)\n",
    "print \"Average PPMI: \", np.mean([ppmiVal for _,_,ppmiVal in posEval])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Examples of Evaluation on Negative Relations (PPMI): \n",
      "[('gun', 'bullet', 0.0), ('bus', 'light', 0.0), ('truck', 'inside', 0.0), ('car', 'rear', 0.0), ('shirt', 'sleeve', 5.9084201543816377)]\n",
      "Average PPMI:  1.1253105496\n"
     ]
    }
   ],
   "source": [
    "print \"Examples of Evaluation on Negative Relations (PPMI): \"\n",
    "print random.sample(negEval, 5)\n",
    "print \"Average PPMI: \", np.mean([ppmiVal for _,_,ppmiVal in negEval])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Cosine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1min 2s, sys: 579 ms, total: 1min 2s\n",
      "Wall time: 9.26 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "ds.build_similarity_matrix('cosine')\n",
    "posEval, negEval = bless_evaluator(ds.simMatrix, indexers=[ds.t2i,ds.t2i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Examples of Evaluation on Positive Relations (Cosine): \n",
      "[('cello', 'object', 0.51162200364617516), ('turtle', 'food', 0.63942938366435298), ('lizard', 'reptile', 0.58609607123821839), ('coyote', 'creature', 0.56094431225012498), ('gun', 'artifact', 0.38685962947461333)]\n",
      "Average Cosine:  0.573630019172\n"
     ]
    }
   ],
   "source": [
    "print \"Examples of Evaluation on Positive Relations (Cosine): \"\n",
    "print random.sample(posEval, 5)\n",
    "print \"Average Cosine: \", np.mean([cosineVal for _,_,cosineVal in posEval])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Examples of Evaluation on Positive Relations (Cosine): \n",
      "[('pub', 'owner', 0.58423573680460572), ('dolphin', 'mouth', 0.64266747703986804), ('box', 'bottom', 0.52428287683330366), ('pub', 'customer', 0.54500702478979579), ('hotel', 'window', 0.67824965328035713)]\n",
      "Average Cosine:  0.558184338667\n"
     ]
    }
   ],
   "source": [
    "print \"Examples of Evaluation on Positive Relations (Cosine): \"\n",
    "print random.sample(negEval, 5)\n",
    "print \"Average Cosine: \", np.mean([cosineVal for _,_,cosineVal in negEval])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### C. Acc@1 & Acc@5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Data & Measures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "path = '/Users/jacobsw/Desktop/IMPLEMENTATION_CAMP/CODE/BASIC_TOPICS/DISTRIBUTIONAL_SEMANTICS/ASSIGNMENT_03/BLESS_part.txt'\n",
    "with open(path,'rb') as f:\n",
    "    bless = f.readlines()\n",
    "bless = [line.split('\\t') for line in bless] # split into (concept, _, relation, relatum).\n",
    "cr_pairs = [(c.split('-')[0].lower(),r.split('-')[0].lower(),rel) for c,_,rel,r in bless] # len=4536\n",
    "pos_pairs = [(c,r) for c,r,rel in crPairs if rel=='hyper']\n",
    "neg_pairs = [(c,r) for c,r,rel in crPairs if rel=='mero']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "concepts:  True\n",
      "relata:  False\n"
     ]
    }
   ],
   "source": [
    "cs = list({c for c,_,_ in cr_pairs})\n",
    "rs = list({r for _,r,_ in cr_pairs})\n",
    "print 'concepts: ', all(cs_i in ds.t2i for cs_i in cs)\n",
    "print 'relata: ', all(rs_i in ds.t2i for rs_i in rs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "unseen_relata = filter(lambda rs_i: rs_i not in ds.t2i, rs)\n",
    "cr_pairs = filter(lambda cr: cr[1] not in unseen_relata, crPairs) # len=4527"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from __future__ import division\n",
    "def weighted_jaccard(u,v): return sum(map(min, zip(u,v))) / sum(map(max, zip(u,v)))\n",
    "def csn(u,v): return np.dot(u,v)/(np.dot(u,u)*np.dot(v,v))\n",
    "def get_vector(word): return ds.simMatrix[ds.t2i[word]]\n",
    "cr_dict = {(c,r):rel for c,r,rel in cr_pairs}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### PPMI + Weighted Jaccard Condition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 4.43 s, sys: 1.85 s, total: 6.28 s\n",
      "Wall time: 6.67 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "ds.build_similarity_matrix('ppmi')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 57.5 s, sys: 174 ms, total: 57.6 s\n",
      "Wall time: 57.7 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "concepts = defaultdict(list)\n",
    "for concept, relatum, _ in cr_pairs:\n",
    "    concepts[concept] += [(relatum, weighted_jaccard(get_vector(concept),get_vector(relatum)))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from operator import itemgetter\n",
    "for word in concepts.keys():\n",
    "    concepts[word] = sorted(concepts[word], key=itemgetter(1), reverse=True)\n",
    "# concepts['frog']\n",
    "# [('lizard', 0.091162496824635675),\n",
    "#  ('toad', 0.078255155511223695),\n",
    "#  ('snake', 0.068625132400646119),\n",
    "#  ('turtle', 0.064585659819217031),\n",
    "#  ('vertebrate', 0.063845815047815918),\n",
    "#  ... ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Acc@1 (ppmi): 0.81\n"
     ]
    }
   ],
   "source": [
    "num_concepts = len(concepts)\n",
    "correct = 0\n",
    "for concept,relata in concepts.iteritems():\n",
    "    correct += 1 if cr_dict[(concept,relata[0][0])] in ['hyper','coord'] else 0\n",
    "print 'Acc@1 (ppmi): %.2f' % (correct/num_concepts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Acc@5 (ppmi): 0.71\n"
     ]
    }
   ],
   "source": [
    "num_concepts = len(concepts)*5\n",
    "correct = 0\n",
    "for concept,relata in concepts.iteritems():\n",
    "    for i in xrange(5):\n",
    "        correct += 1 if cr_dict[(concept,relata[i][0])] in ['hyper','coord'] else 0\n",
    "print 'Acc@5 (ppmi): %.2f' % (correct/num_concepts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### PPMI + Cosine Condition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 4.18 s, sys: 1.68 s, total: 5.85 s\n",
      "Wall time: 6.2 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "ds.build_similarity_matrix('ppmi')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 124 ms, sys: 956 µs, total: 125 ms\n",
      "Wall time: 125 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "concepts = defaultdict(list)\n",
    "for concept, relatum, _ in cr_pairs:\n",
    "    concepts[concept] += [(relatum, csn(get_vector(concept),get_vector(relatum)))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from operator import itemgetter\n",
    "for word in concepts.keys():\n",
    "    concepts[word] = sorted(concepts[word], key=itemgetter(1), reverse=True)\n",
    "# concepts['frog']\n",
    "# [('lizard', 0.091162496824635675),\n",
    "#  ('toad', 0.078255155511223695),\n",
    "#  ('snake', 0.068625132400646119),\n",
    "#  ('turtle', 0.064585659819217031),\n",
    "#  ('vertebrate', 0.063845815047815918),\n",
    "#  ... ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Acc@1 (ppmi): 0.81\n"
     ]
    }
   ],
   "source": [
    "num_concepts = len(concepts)\n",
    "correct = 0\n",
    "for concept,relata in concepts.iteritems():\n",
    "    correct += 1 if cr_dict[(concept,relata[0][0])] in ['hyper','coord'] else 0\n",
    "print 'Acc@1 (ppmi): %.2f' % (correct/num_concepts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Acc@5 (ppmi): 0.74\n"
     ]
    }
   ],
   "source": [
    "num_concepts = len(concepts)*5\n",
    "correct = 0\n",
    "for concept,relata in concepts.iteritems():\n",
    "    for i in xrange(5):\n",
    "        correct += 1 if cr_dict[(concept,relata[i][0])] in ['hyper','coord'] else 0\n",
    "print 'Acc@5 (ppmi): %.2f' % (correct/num_concepts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
