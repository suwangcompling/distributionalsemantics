{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Distributional Semantics Model: Narrow Word-Window (-2,+2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### A. Data-Loading Facilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "os.chdir(\"/Users/jacobsw/Desktop/IMPLEMENTATION_CAMP/CODE/BASIC_TOPICS/DISTRIBUTIONAL_SEMANTICS/ASSIGNMENT_03\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "stopwords = stopwords.words('english')\n",
    "from collections import defaultdict, Counter\n",
    "from functools import partial\n",
    "from itertools import permutations, product\n",
    "punctuation = '!\"#$%&\\'()*+,-/:;<=>?@[\\\\]^_`{|}~'\n",
    "from operator import itemgetter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def load_wiki(cutoffFreq=20):\n",
    "    \n",
    "    print \"... extracting data\"\n",
    "    with open('wikicorpus.txt','rb') as f:\n",
    "        raw = f.readlines()\n",
    "    raw = [sent[4:].split() for sent in raw if sent.startswith('<c>')] \n",
    "        # sent[4:]: get rid of initial <c>.\n",
    "        # extract sentences; split sentences into word complexes.\n",
    "    raw = [[map(partial(str.split, word), '|') for word in sent] for sent in raw] \n",
    "        # split word complexes into words.\n",
    "    \n",
    "    print \"... cleaning data\"\n",
    "    tagged_sents = [[(word[0][1].lower(),word[0][2]) for word in sent if len(word[0])>1 \n",
    "                      and word[0][1].lower() not in stopwords\n",
    "                      and word[0][1] not in punctuation] for sent in raw]\n",
    "    \n",
    "    print \"... getting top-%d frequent context words and top-50 frequent nouns\" % cutoffFreq\n",
    "    all_tokens = [word for tagged_sent in tagged_sents for word,tag in tagged_sent]\n",
    "        # type: list of words.\n",
    "    context_fdist = Counter(all_tokens)\n",
    "    context_vocab = list({word for word,freq in context_fdist.iteritems() if freq>=20})\n",
    "    n_tokens = [word for tagged_sent in tagged_sents for word,tag in tagged_sent if tag.startswith('N')]\n",
    "    n_fdist = Counter(n_tokens)\n",
    "    n_vocab = list({word for word,freq in n_fdist.iteritems() if freq>=50})\n",
    "    \n",
    "    sents = [[word for word,tag in tagged_sent if word in context_vocab] for tagged_sent in tagged_sents]\n",
    "    \n",
    "    return (n_vocab, context_vocab, sents)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "... extracting data\n",
      "... cleaning data\n",
      "... getting top-20 frequent context words and top-50 frequent nouns\n",
      "CPU times: user 19min 23s, sys: 9.23 s, total: 19min 32s\n",
      "Wall time: 19min 30s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "n_vocab, context_vocab, sents = load_wiki()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import cPickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "cleaned_data_path = '/Users/jacobsw/Desktop/IMPLEMENTATION_CAMP/CODE/BASIC_TOPICS/DISTRIBUTIONAL_SEMANTICS/CODE/CLEANED_DATA/'\n",
    "cPickle.dump((n_vocab,context_vocab,sents), open(cleaned_data_path+'cleaned_wiki.p', 'wb')) \n",
    "# obj = cPickle.load(open('save.p', 'rb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### B1. Analyzer: Cooccurrence Matrix Based"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### A. Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# SIMILARITY MEASURES\n",
    "def cosine(w2w):\n",
    "    w2w_norm = w2w / np.apply_along_axis(lambda r: np.sqrt(np.dot(r,r))\n",
    "                               , 1, w2w)[:,np.newaxis]\n",
    "    return np.dot(w2w_norm, w2w_norm.T)\n",
    "    \n",
    "def ppmi(w2w):\n",
    "    rowSums, colSums, totalSums = w2w.sum(axis=1), w2w.sum(axis=0), w2w.sum()\n",
    "    pwi, pwj, ppmiMatrix = rowSums/totalSums, colSums/totalSums, w2w/totalSums\n",
    "    ppmiMatrix /= pwi[:,np.newaxis] # * 1/pwi by row.\n",
    "    ppmiMatrix /= pwj # * 1/pwj by col.\n",
    "    ppmiMatrix = np.nan_to_num(np.log(ppmiMatrix)) # compute pmi.\n",
    "    ppmiMatrix = np.maximum(ppmiMatrix, 0) # compute ppmi.\n",
    "    return ppmiMatrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class SimpleDistSem:\n",
    "    \n",
    "    def __init__(self, target_vocab, context_vocab, sents):\n",
    "        self.sents = sents \n",
    "            # a list of sents considered in the corpus.\n",
    "            #  in this case, words in context_vocab.\n",
    "        self.vocab = target_vocab\n",
    "        self.context = context_vocab\n",
    "        self.t2i = {t:i for i,t in enumerate(self.vocab)}\n",
    "        self.c2i = {word:i for i,word in enumerate(self.context)}\n",
    "        self.algos = {'ppmi':ppmi, 'cosine':cosine}\n",
    "    \n",
    "    def build_t2c_matrix(self, win_size):\n",
    "        \n",
    "        print \"... counting words\"\n",
    "        cooccurrenceDict = defaultdict(int)\n",
    "        for sent in self.sents:\n",
    "            for i,target in enumerate(sent):\n",
    "                contexts = sent[max(0,i-win_size):i] + \\\n",
    "                           sent[min(i+1,len(sent)):min(i+1+win_size,len(sent))]\n",
    "                for context in contexts:\n",
    "                    cooccurrenceDict[(target,context)] += 1\n",
    "        \n",
    "        print \"... building cooccurrence matrix\"\n",
    "        self.t2c = np.zeros((len(self.vocab),len(self.context)))\n",
    "        for target in self.vocab:\n",
    "            for context in self.context:\n",
    "                self.t2c[self.t2i[target]][self.c2i[context]] = cooccurrenceDict[(target,context)]\n",
    "    \n",
    "    def build_similarity_matrix(self, similarity='ppmi'):\n",
    "        self.sim_algo = similarity\n",
    "        self.simMatrix = self.algos[similarity](self.t2c)\n",
    "    \n",
    "    def k_most_similar(self, words, k=20):\n",
    "        assert len(words)==len(filter(lambda w:1 if w in self.vocab else 0, words))\n",
    "        w2sim = {}\n",
    "        for word in words:\n",
    "            simList = self.simMatrix[self.t2i[word]]\n",
    "            if self.sim_algo=='ppmi':\n",
    "                w2sim[word] = map(lambda idx:(self.context[idx],\n",
    "                                              self.simMatrix[self.t2i[word]][idx]),\n",
    "                                  np.argsort(simList)[::-1][1:k+1])\n",
    "            else:\n",
    "                w2sim[word] = map(lambda idx:(self.vocab[idx],\n",
    "                                              self.simMatrix[self.t2i[word]][idx]),\n",
    "                                  np.argsort(simList)[::-1][1:k+1])                \n",
    "            # [1:k+1]: skip self-similarty.\n",
    "        return w2sim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 8.09 ms, sys: 9.56 ms, total: 17.7 ms\n",
      "Wall time: 31.8 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "ds = SimpleDistSem(n_vocab,context_vocab,sents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "... counting words\n",
      "... building cooccurrence matrix\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "ds.build_t2c_matrix(win_size=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "model_path = '/Users/jacobsw/Desktop/IMPLEMENTATION_CAMP/CODE/BASIC_TOPICS/DISTRIBUTIONAL_SEMANTICS/CODE/MODELS/'\n",
    "cPickle.dump(ds.t2c, open(model_path+'t2c_matrix.p', 'wb')) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### b. Evaluator: K-Frequent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 4.16 s, sys: 2.1 s, total: 6.26 s\n",
      "Wall time: 6.57 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "ds.build_similarity_matrix('ppmi')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6971, 18609)"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds.simMatrix.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-101-ce424af63c09>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mget_ipython\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_cell_magic\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mu'time'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34mu''\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34mu\"words = ['car','bus','hospital','hotel','gun','bomb','horse','fox','table','bowl','guitar','piano']\\nw2sim = ds.k_most_similar(words)\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/Users/jacobsw/anaconda2/lib/python2.7/site-packages/IPython/core/interactiveshell.pyc\u001b[0m in \u001b[0;36mrun_cell_magic\u001b[0;34m(self, magic_name, line, cell)\u001b[0m\n\u001b[1;32m   2118\u001b[0m             \u001b[0mmagic_arg_s\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvar_expand\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mline\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstack_depth\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2119\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuiltin_trap\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2120\u001b[0;31m                 \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmagic_arg_s\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcell\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2121\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2122\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<decorator-gen-60>\u001b[0m in \u001b[0;36mtime\u001b[0;34m(self, line, cell, local_ns)\u001b[0m\n",
      "\u001b[0;32m/Users/jacobsw/anaconda2/lib/python2.7/site-packages/IPython/core/magic.pyc\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m(f, *a, **k)\u001b[0m\n\u001b[1;32m    191\u001b[0m     \u001b[0;31m# but it's overkill for just that one bit of state.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    192\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mmagic_deco\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 193\u001b[0;31m         \u001b[0mcall\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mlambda\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    194\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    195\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcallable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/jacobsw/anaconda2/lib/python2.7/site-packages/IPython/core/magics/execution.pyc\u001b[0m in \u001b[0;36mtime\u001b[0;34m(self, line, cell, local_ns)\u001b[0m\n\u001b[1;32m   1175\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1176\u001b[0m             \u001b[0mst\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclock2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1177\u001b[0;31m             \u001b[0;32mexec\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mglob\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlocal_ns\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1178\u001b[0m             \u001b[0mend\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclock2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1179\u001b[0m             \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<timed exec>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m<ipython-input-96-b30e2906eed2>\u001b[0m in \u001b[0;36mk_most_similar\u001b[0;34m(self, words, k)\u001b[0m\n\u001b[1;32m     40\u001b[0m             w2sim[word] = map(lambda idx:(self.vocab[idx],\n\u001b[1;32m     41\u001b[0m                                           self.simMatrix[self.t2i[word]][idx]),\n\u001b[0;32m---> 42\u001b[0;31m                               np.argsort(simList)[::-1][1:k+1])\n\u001b[0m\u001b[1;32m     43\u001b[0m             \u001b[0;31m# [1:k+1]: skip self-similarty.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     44\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mw2sim\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-96-b30e2906eed2>\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m(idx)\u001b[0m\n\u001b[1;32m     38\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mword\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mwords\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m             \u001b[0msimList\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msimMatrix\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mt2i\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mword\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 40\u001b[0;31m             w2sim[word] = map(lambda idx:(self.vocab[idx],\n\u001b[0m\u001b[1;32m     41\u001b[0m                                           self.simMatrix[self.t2i[word]][idx]),\n\u001b[1;32m     42\u001b[0m                               np.argsort(simList)[::-1][1:k+1])\n",
      "\u001b[0;31mIndexError\u001b[0m: list index out of range"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "words = ['car','bus','hospital','hotel','gun','bomb','horse','fox','table','bowl','guitar','piano']\n",
    "w2sim = ds.k_most_similar(words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(u'brabham', 4.7766275467196584),\n",
       " (u'bogie', 4.7055917736029063),\n",
       " (u'racing', 4.5943839798650412),\n",
       " (u'earnhardt', 4.366924146418258),\n",
       " (u'bentley', 4.3662664679992869),\n",
       " (u'brake', 4.3409486600149974),\n",
       " (u'cable', 4.3255062609917951),\n",
       " (u'clutch', 4.2657252387774101),\n",
       " (u'audi', 4.2176254439829988),\n",
       " (u'aston', 4.1303838909076473),\n",
       " (u'chassis', 4.128978409298913),\n",
       " (u'truck', 4.0516232018194867),\n",
       " (u'grip', 3.9780431663256288),\n",
       " (u'car', 3.9593991033033911),\n",
       " (u'installation', 3.9023097782248346),\n",
       " (u'motors', 3.8902269603187118),\n",
       " (u'prix', 3.8135937342977959),\n",
       " (u'tire', 3.8054304236586352),\n",
       " (u'compact', 3.7933090631262902),\n",
       " (u'crash', 3.7869508643837979)]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w2sim['car']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 20.8 s, sys: 272 ms, total: 21 s\n",
      "Wall time: 3.54 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "ds.build_similarity_matrix('cosine')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 12 ms, sys: 649 µs, total: 12.6 ms\n",
      "Wall time: 11.8 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "words = ['car','bus','hospital','hotel','gun','bomb','horse','fox','table','bowl','guitar','piano']\n",
    "w2sim = ds.k_most_similar(words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(u'piano', 0.99999999999999956),\n",
       " (u'cello', 0.84187590856948435),\n",
       " (u'instrument', 0.83042142568560717),\n",
       " (u'piece', 0.82429209108329438),\n",
       " (u'concerto', 0.82214317322249686),\n",
       " (u'style', 0.80750453162609459),\n",
       " (u'composition', 0.80621877549042775),\n",
       " (u'music', 0.80335035929212972),\n",
       " (u'sound', 0.80095692227873194),\n",
       " (u'sonata', 0.79813149147023077),\n",
       " (u'violin', 0.7963416282295428),\n",
       " (u'work', 0.79472264984458352),\n",
       " (u'arrangement', 0.79370701901133001),\n",
       " (u'performance', 0.79002073528385708),\n",
       " (u'career', 0.78407199429323937),\n",
       " (u'influence', 0.78106297327464669),\n",
       " (u'tone', 0.78064091165776106),\n",
       " (u'theme', 0.78052972790344377),\n",
       " (u'guitar', 0.78019642679685886),\n",
       " (u'history', 0.78010361181095722)]"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w2sim['piano']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6971, 6971)"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds.simMatrix.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### c. Evaluator: BLESS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def bless_evaluator(simMatrix, indexers=[t2i,c2i]):\n",
    "    t2i,c2i = indexers\n",
    "    path = '/Users/jacobsw/Desktop/IMPLEMENTATION_CAMP/CODE/BASIC_TOPICS/DISTRIBUTIONAL_SEMANTICS/ASSIGNMENT_03/BLESS_part.txt'\n",
    "    with open(path,'rb') as f:\n",
    "        bless = f.readlines()\n",
    "    bless = [line.split('\\t') for line in bless] # split into (concept, _, relation, relatum).\n",
    "    crPairs = [(c.split('-')[0],r.split('-')[0],rel) for c,_,rel,r in bless]\n",
    "    posPairs = [(c,r) for c,r,rel in crPairs if rel=='hyper']\n",
    "    negPairs = [(c,r) for c,r,rel in crPairs if rel=='mero']\n",
    "    \n",
    "    return [map(lambda (c,r):(c,r,simMatrix[t2i[c]][c2i[r]]), posPairs),\n",
    "            map(lambda (c,r):(c,r,simMatrix[t2i[c]][c2i[r]]), negPairs)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### PPMI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 4.05 s, sys: 1.53 s, total: 5.58 s\n",
      "Wall time: 5.59 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "ds.build_similarity_matrix('ppmi')\n",
    "posEval, negEval = bless_evaluator(ds.simMatrix, indexers=[ds.t2i,c2i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Examples of Evaluation on Positive Relations (PPMI): \n",
      "[('shirt', 'garment', 0.0), ('flute', 'object', 0.0), ('bomb', 'object', 0.0), ('jet', 'plane', 0.0), ('library', 'construction', 0.0)]\n",
      "Average PPMI:  0.111013883294\n"
     ]
    }
   ],
   "source": [
    "print \"Examples of Evaluation on Positive Relations (PPMI): \"\n",
    "print random.sample(posEval, 5)\n",
    "print \"Average PPMI: \", np.mean([ppmiVal for _,_,ppmiVal in posEval])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Examples of Evaluation on Negative Relations (PPMI): \n",
      "[('bowl', 'clay', 0.0), ('oak', 'trunk', 0.0), ('van', 'seat', 0.0), ('table', 'cover', 0.0), ('tiger', 'eye', 0.0)]\n",
      "Average PPMI:  0.0664503314987\n"
     ]
    }
   ],
   "source": [
    "print \"Examples of Evaluation on Negative Relations (PPMI): \"\n",
    "print random.sample(negEval, 5)\n",
    "print \"Average PPMI: \", np.mean([ppmiVal for _,_,ppmiVal in negEval])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Cosine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 57.3 s, sys: 717 ms, total: 58 s\n",
      "Wall time: 9.38 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "ds.build_similarity_matrix('cosine')\n",
    "posEval, negEval = bless_evaluator(ds.simMatrix, indexers=[ds.t2i,ds.t2i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Examples of Evaluation on Positive Relations (Cosine): \n",
      "[('dagger', 'object', 0.65870104098146565), ('horse', 'mammal', 0.65559039669903407), ('sword', 'device', 0.73989582866053138), ('bag', 'object', 0.78645090412740359), ('ferry', 'craft', 0.45008036681292374)]\n",
      "Average Cosine:  0.573630019172\n"
     ]
    }
   ],
   "source": [
    "print \"Examples of Evaluation on Positive Relations (Cosine): \"\n",
    "print random.sample(posEval, 5)\n",
    "print \"Average Cosine: \", np.mean([cosineVal for _,_,cosineVal in posEval])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Examples of Evaluation on Positive Relations (Cosine): \n",
      "[('restaurant', 'seat', 0.615422359359027), ('restaurant', 'chef', 0.50549522953873005), ('cannon', 'charge', 0.53031500999697223), ('goat', 'mouth', 0.40557216613367419), ('box', 'side', 0.58359322474165565)]\n",
      "Average Cosine:  0.558184338667\n"
     ]
    }
   ],
   "source": [
    "print \"Examples of Evaluation on Positive Relations (Cosine): \"\n",
    "print random.sample(negEval, 5)\n",
    "print \"Average Cosine: \", np.mean([cosineVal for _,_,cosineVal in negEval])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
