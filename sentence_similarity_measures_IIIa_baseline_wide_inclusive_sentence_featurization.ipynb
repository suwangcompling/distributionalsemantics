{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Sentence Similarity Measures IIIa: Baseline Wide-Inclusive Sentence Featurization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## 0. Contents\n",
    "\n",
    "* I. Corpora:\n",
    "    * MSR Paraphrase Corpus\n",
    "    * Brown\n",
    "* II. Discriminativity Weighting (Brown, SpaCy lemmatization)\n",
    "* III. Featurization:\n",
    "    * Features:\n",
    "        * Unigram Prec/Rec (Wan et al. 2006) \n",
    "        * Bleu Prec/Rec (Papineni et al. 2002)\n",
    "        * Dependency Prec/Rec (Wan et al. 2006; Moll$\\acute{a}$ 2003; Hovy et al. 2015)\n",
    "        * F1 for Unigram, Bleu & Dependency\n",
    "        * Tree Edit Distance (Zhang & Sasha Algorithm)\n",
    "        * Sentence Lengths (Wan et al. 2006)\n",
    "    * Featurization Function\n",
    "* IV. Paraphrase Classifier:\n",
    "    * Training: MSR Paraphrase Corpus\n",
    "    * Classifier Types:\n",
    "        * Logistic\n",
    "        * SVM\n",
    "* V. Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## I. Corpora"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from nltk.corpus import brown\n",
    "from spacy.en import English\n",
    "from collections import defaultdict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "parser = English()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Load MSR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train_path = \"/Users/jacobsw/Desktop/WORK/OJO_CODE/SENTENCE_SIMILARITIES/CORPORA/paraphrase/msr_paraphrase_train.txt\"\n",
    "test_path = \"/Users/jacobsw/Desktop/WORK/OJO_CODE/SENTENCE_SIMILARITIES/CORPORA/paraphrase/msr_paraphrase_test.txt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Quality</th>\n",
       "      <th>#1 ID</th>\n",
       "      <th>#2 ID</th>\n",
       "      <th>#1 String</th>\n",
       "      <th>#2 String</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>702876</td>\n",
       "      <td>702977</td>\n",
       "      <td>Amrozi accused his brother, whom he called the...</td>\n",
       "      <td>Referring to him as only the witness, Amrozi a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>2108705</td>\n",
       "      <td>2108831</td>\n",
       "      <td>Yucaipa owned Dominick's before selling the ch...</td>\n",
       "      <td>Yucaipa bought Dominick's in 1995 for $693 mil...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>1330381</td>\n",
       "      <td>1330521</td>\n",
       "      <td>They had published an advertisement on the Int...</td>\n",
       "      <td>On June 10, the ship's owners had published an...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>3344667</td>\n",
       "      <td>3344648</td>\n",
       "      <td>Around 0335 GMT, Tab shares were up 19 cents, ...</td>\n",
       "      <td>Tab shares jumped 20 cents, or 4.6%, to set a ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>1236820</td>\n",
       "      <td>1236712</td>\n",
       "      <td>The stock rose $2.11, or about 11 percent, to ...</td>\n",
       "      <td>PG&amp;E Corp. shares jumped $1.63 or 8 percent to...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Quality    #1 ID    #2 ID  \\\n",
       "0        1   702876   702977   \n",
       "1        0  2108705  2108831   \n",
       "2        1  1330381  1330521   \n",
       "3        0  3344667  3344648   \n",
       "4        1  1236820  1236712   \n",
       "\n",
       "                                           #1 String  \\\n",
       "0  Amrozi accused his brother, whom he called the...   \n",
       "1  Yucaipa owned Dominick's before selling the ch...   \n",
       "2  They had published an advertisement on the Int...   \n",
       "3  Around 0335 GMT, Tab shares were up 19 cents, ...   \n",
       "4  The stock rose $2.11, or about 11 percent, to ...   \n",
       "\n",
       "                                           #2 String  \n",
       "0  Referring to him as only the witness, Amrozi a...  \n",
       "1  Yucaipa bought Dominick's in 1995 for $693 mil...  \n",
       "2  On June 10, the ship's owners had published an...  \n",
       "3  Tab shares jumped 20 cents, or 4.6%, to set a ...  \n",
       "4  PG&E Corp. shares jumped $1.63 or 8 percent to...  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train = pd.read_table(train_path, encoding='utf-8-sig')\n",
    "df_test = pd.read_table(test_path, encoding='utf-8-sig')\n",
    "df_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4076, 5)\n",
      "(1725, 5)\n"
     ]
    }
   ],
   "source": [
    "print df_train.shape\n",
    "print df_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Quality                                                      1\n",
       "#1 ID                                                   702876\n",
       "#2 ID                                                   702977\n",
       "#1 String    Amrozi accused his brother, whom he called the...\n",
       "#2 String    Referring to him as only the witness, Amrozi a...\n",
       "Name: 0, dtype: object"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.ix[0] # NB: index Quality is actually weirdly 'ï»¿Quality'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "u'Amrozi accused his brother, whom he called the witness, of deliberately distorting his evidence.'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.ix[0]['#1 String']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Make Train/Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dep_lemmas = lambda parsed_s: {(token.head.lemma_,token.lemma_) for token in parsed_s\n",
    "                             if token.head.lemma_!=token.lemma_} # eliminte (v, ROOT, v) cases\n",
    "dep_tokens = lambda parsed_s: {(token.head.orth_,token.orth_) for token in parsed_s\n",
    "                             if token.head.lemma_!=token.lemma_}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "get_root = lambda parsed_s: [token for token in parsed_s if token.lemma_==token.head.lemma_][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def parse_msr(df, indexer):\n",
    "    \n",
    "    X_dic, Y_dic = defaultdict(lambda x: defaultdict(list)), \\\n",
    "                   defaultdict(lambda x: defaultdict(list))\n",
    "    \n",
    "    for i in indexer:\n",
    "        \n",
    "        entry_dic = defaultdict(list)\n",
    "        s1, s2 = df.ix[i]['#1 String'][:-1], \\\n",
    "                 df.ix[i]['#2 String'][:-1] \n",
    "                # get rid of period, which causes problem in distinguishing identical tokens.\n",
    "        \n",
    "        parsed_s1, parsed_s2 = parser(unicode(s1)), parser(unicode(s2))\n",
    "        \n",
    "        entry_dic['s1'] = [token.orth_ for token in parsed_s1]\n",
    "        entry_dic['s2'] = [token.orth_ for token in parsed_s2]\n",
    "        entry_dic['s1_lm'] = [token.lemma_ for token in parsed_s1]\n",
    "        entry_dic['s2_lm'] = [token.lemma_ for token in parsed_s2]\n",
    "        \n",
    "        parsed_lm_s1, parsed_lm_s2 = parser(' '.join(entry_dic['s1_lm'])), \\\n",
    "                                    parser(' '.join(entry_dic['s2_lm'])) # parse on lemmas.\n",
    "        \n",
    "        entry_dic['s1_dep_lm'] = dep_lemmas(parsed_lm_s1) # for dep lemma features.\n",
    "        entry_dic['s2_dep_lm'] = dep_lemmas(parsed_lm_s2)\n",
    "        entry_dic['s1_dep_tk'] = dep_tokens(parsed_s1) # for dep token features.\n",
    "        entry_dic['s2_dep_tk'] = dep_tokens(parsed_s2) \n",
    "        entry_dic['s1_root_lm'] = get_root(parsed_lm_s1)\n",
    "        entry_dic['s2_root_lm'] = get_root(parsed_lm_s2)\n",
    "        entry_dic['s1_root_tk'] = get_root(parsed_s1)\n",
    "        entry_dic['s2_root_tk'] = get_root(parsed_s2)\n",
    "        entry_dic['s1_id'] = df.ix[i]['#1 ID'] # for error analysis later.\n",
    "        entry_dic['s2_id'] = df.ix[i]['#2 ID']\n",
    "        X_dic[i] = entry_dic\n",
    "        Y_dic[i] = df.ix[i]['Quality']\n",
    "    \n",
    "    return X_dic, Y_dic\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 30.3 s, sys: 311 ms, total: 30.6 s\n",
      "Wall time: 30.7 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "X_train, Y_train = parse_msr(df_train, df_train.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 12.7 s, sys: 142 ms, total: 12.8 s\n",
      "Wall time: 12.9 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "X_test, Y_test = parse_msr(df_test, df_test.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sentence 1:  [u'Amrozi', u'accused', u'his', u'brother', u',', u'whom', u'he', u'called', u'the', u'witness', u',', u'of', u'deliberately', u'distorting', u'his', u'evidence']\n",
      "\n",
      "sentence 2:  [u'Referring', u'to', u'him', u'as', u'only', u'the', u'witness', u',', u'Amrozi', u'accused', u'his', u'brother', u'of', u'deliberately', u'distorting', u'his', u'evidence']\n",
      "\n",
      "paraphrase label:  1\n"
     ]
    }
   ],
   "source": [
    "print 'sentence 1: ', X_train[0]['s1']; print\n",
    "print 'sentence 2: ', X_train[0]['s2']; print\n",
    "print 'paraphrase label: ', Y_train[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Load Brown"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def parse_brown():\n",
    "    \n",
    "    sents = brown.sents()\n",
    "    parsed_sents = [parser(' '.join(sent)) for sent in sents]\n",
    "    lemma_words = [token.lemma_ for parsed_sent in parsed_sents for token in parsed_sent]\n",
    "    \n",
    "    return lemma_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1min 43s, sys: 910 ms, total: 1min 44s\n",
      "Wall time: 1min 44s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "brown_words = parse_brown()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1188973"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "N = len(brown_words)\n",
    "N"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## I. Discriminativity Weighting (IDF)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Math**\n",
    "\n",
    "* $IDF(w) = log\\frac{N}{df_w}$, where $N$ is the number of words in a corpus; $df_w$ is word $w$'s frequency in the corpus."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from __future__ import division"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def log(x):\n",
    "    return np.log(x) if x>0 else 0 \n",
    "    # intuitively N > word_count(w) for any w,\n",
    "    #  therefore we cannot let idf(w) be negative\n",
    "    #  even when word_count(w) = 0 for w.\n",
    "def div(x, y):\n",
    "    return x/y if y!=0 else 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def idf(w):\n",
    "    \n",
    "    return log(div(N,brown_words.count(w)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'the':  2.77258872224\n",
      "'discriminate':  12.0426886361\n"
     ]
    }
   ],
   "source": [
    "print \"'the': \", idf('the')\n",
    "print \"'discriminate': \", idf('discriminate')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## IIa. Features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### A.  Unigram Prec/Rec"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Math**\n",
    "\n",
    "* $Uni\\_Prec(s_1,s_2) = \\frac{word\\_overlap(s_1,s_2)}{word\\_count(s_1)}$ (cf. Wan et al. 2006:133, weighted by $IDF$)\n",
    "\n",
    "\n",
    "* $Uni\\_Rec(s_1,s_2) = \\frac{word\\_overlap(s_1,s_2)}{word\\_count(s_2)}$ (cf. ibid.)\n",
    "\n",
    "\n",
    "* If needed, $TF-IDF: \\frac{\\left(\\sum_{w\\in s_1\\cap s_2}log\\frac{N}{df_w}\\right)}{\\left(\\sum_{w\\in s_1}log\\frac{N}{df_w}\\right)}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def intersection(s1, s2):\n",
    "    return set(s1).intersection(set(s2))\n",
    "\n",
    "def word_overlap(s1, s2):\n",
    "    return len(intersection(s1,s2))\n",
    "\n",
    "def lemmatize(s):\n",
    "    return [token.lemma_ for token in parser(' '.join(s))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def uni_prec(s1, s2): # s1,s2 assumed to be lists of words (lemmas or tokens)\n",
    "\n",
    "    return div(word_overlap(s1,s2),len(s1))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def uni_rec(s1, s2): # s1,s2 assumed to be lists of words (lemmas or tokens)\n",
    "\n",
    "    return div(word_overlap(s1,s2),len(s2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "s0 = X_train[0]['s1']\n",
    "s1 = X_train[0]['s2'] # known to be the paraphrase of q\n",
    "s2 = X_train[1]['s1'] # known to not be the paraphrase of q\n",
    "s0_lm = X_train[0]['s1_lm']\n",
    "s1_lm = X_train[0]['s2_lm']\n",
    "s2_lm = X_train[1]['s1_lm']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6875\n",
      "0.0625\n",
      "0.6875\n",
      "0.0625\n",
      "CPU times: user 274 Âµs, sys: 184 Âµs, total: 458 Âµs\n",
      "Wall time: 265 Âµs\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "print uni_prec(s0,s1)\n",
    "print uni_prec(s0,s2)\n",
    "print uni_prec(s0_lm,s1_lm)\n",
    "print uni_prec(s0_lm,s2_lm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.647058823529\n",
      "0.0625\n",
      "0.647058823529\n",
      "0.0625\n",
      "CPU times: user 240 Âµs, sys: 152 Âµs, total: 392 Âµs\n",
      "Wall time: 297 Âµs\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "print uni_rec(s0,s1)\n",
    "print uni_rec(s0,s2)\n",
    "print uni_rec(s0_lm,s1_lm)\n",
    "print uni_rec(s0_lm,s2_lm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### B. BLEU Prec/Rec"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**NB** (cf. Wan et al. 2006:133)\n",
    "\n",
    "* \"... Bleu metric uses the geometric average of unigram, bigram and trigram precision scores.\"\n",
    "* \"... by reversing [two sentences], ... a recall version of Bleu is obtained.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from nltk import bleu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def bleu_prec(s1, s2, lemmatized=False): # s1 as the 'hypothesis'\n",
    "\n",
    "    return bleu(s2,s1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def bleu_rec(s1, s2, lemmatized=False): # s2 as the 'hypothesis' \n",
    "    \n",
    "    return bleu(s1,s2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5\n",
      "0\n",
      "0.5\n",
      "0\n",
      "CPU times: user 6.78 ms, sys: 2.31 ms, total: 9.1 ms\n",
      "Wall time: 7.54 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "print bleu_prec(s0,s1)\n",
    "print bleu_prec(s0,s2)\n",
    "print bleu_prec(s0_lm,s1_lm)\n",
    "print bleu_prec(s0_lm,s2_lm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.492479060505\n",
      "0\n",
      "0.492479060505\n",
      "0\n",
      "CPU times: user 7.09 ms, sys: 2.98 ms, total: 10.1 ms\n",
      "Wall time: 7.75 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "print bleu_rec(s0,s1)\n",
    "print bleu_rec(s0,s2)\n",
    "print bleu_rec(s0_lm,s1_lm)\n",
    "print bleu_rec(s0_lm,s2_lm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### C. Dependency Prec/Rec"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Math**\n",
    "\n",
    "* $Dep\\_Prec(s_1,s_2) = \\frac{|dep\\_pair(s_1)|\\cap|dep\\_pair(s_2)|}{|dep\\_pair(s_1)|}$ (cf. Wan et al. 2006:134)\n",
    "\n",
    "\n",
    "* $Dep\\_Rec(s_1,s_2) = \\frac{|dep\\_pair(s_1)|\\cap|dep\\_pair(s_2)|}{|dep\\_pair(s_2)|}$ (cf. ibid.)\n",
    "\n",
    "**NB**: $relation$ in the reference confuses *dependency pair* with *dependency relation*. $relation$ refers to \"... a pair of words in a parent-child relationship within the dependency tree, referred to as head-modifier relationship. ... we ignore the label of the relationships which indicates the semantic role\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def dep_prec(dep_pairs_s1, dep_pairs_s2):\n",
    "    \n",
    "    return div(len(dep_pairs_s1.intersection(dep_pairs_s2)),\n",
    "               len(dep_pairs_s1))\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def dep_rec(dep_pairs_s1, dep_pairs_s2):\n",
    "    \n",
    "    return div(len(dep_pairs_s1.intersection(dep_pairs_s2)),\n",
    "               len(dep_pairs_s2))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "s0_dep_tk = X_train[0]['s1_dep_tk']\n",
    "s1_dep_tk = X_train[0]['s2_dep_tk']\n",
    "s2_dep_tk = X_train[1]['s1_dep_tk']\n",
    "s0_dep_lm = X_train[0]['s1_dep_lm']\n",
    "s1_dep_lm = X_train[0]['s2_dep_lm']\n",
    "s2_dep_lm = X_train[1]['s1_dep_lm']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.571428571429\n",
      "0.0\n",
      "0.533333333333\n",
      "0.0\n",
      "CPU times: user 183 Âµs, sys: 68 Âµs, total: 251 Âµs\n",
      "Wall time: 198 Âµs\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "print dep_prec(s0_dep_tk,s1_dep_tk)\n",
    "print dep_prec(s0_dep_tk,s2_dep_tk)\n",
    "print dep_prec(s0_dep_lm,s1_dep_lm)\n",
    "print dep_prec(s0_dep_lm,s2_dep_lm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.571428571429\n",
      "0.0\n",
      "0.533333333333\n",
      "0.0\n",
      "CPU times: user 224 Âµs, sys: 87 Âµs, total: 311 Âµs\n",
      "Wall time: 264 Âµs\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "print dep_prec(s0_dep_tk,s1_dep_tk)\n",
    "print dep_prec(s0_dep_tk,s2_dep_tk)\n",
    "print dep_prec(s0_dep_lm,s1_dep_lm)\n",
    "print dep_prec(s0_dep_lm,s2_dep_lm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### D. F1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Math**\n",
    "\n",
    "* $F1 = 2\\cdot\\frac{prec\\cdot rec}{prec + rec}$ (cf. https://en.wikipedia.org/wiki/F1_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def f1(s1_info, s2_info, fn_prec, fn_rec):\n",
    "    # s1_info, s2_info: could be s1/s2 as lists of words, or dep-pairs.\n",
    "    \n",
    "    prec, rec = fn_prec(s1_info,s2_info), fn_rec(s1_info,s2_info)\n",
    "    \n",
    "    return prec, rec, 2*div(prec*rec,prec+rec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.666666666667\n",
      "0.0625\n",
      "0.666666666667\n",
      "0.0625\n",
      "CPU times: user 199 Âµs, sys: 81 Âµs, total: 280 Âµs\n",
      "Wall time: 220 Âµs\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "print f1(s0,s1,uni_prec,uni_rec)[2]\n",
    "print f1(s0,s2,uni_prec,uni_rec)[2]\n",
    "print f1(s0_lm,s1_lm,uni_prec,uni_rec)[2]\n",
    "print f1(s0_lm,s2_lm,uni_prec,uni_rec)[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.496211033666\n",
      "0\n",
      "0.496211033666\n",
      "0\n",
      "CPU times: user 12.5 ms, sys: 5.74 ms, total: 18.2 ms\n",
      "Wall time: 14 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "print f1(s0,s1,bleu_prec,bleu_rec)[2]\n",
    "print f1(s0,s2,bleu_prec,bleu_rec)[2]\n",
    "print f1(s0_lm,s1_lm,bleu_prec,bleu_rec)[2]\n",
    "print f1(s0_lm,s2_lm,bleu_prec,bleu_rec)[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.533333333333\n",
      "0\n",
      "0.516129032258\n",
      "0\n",
      "CPU times: user 232 Âµs, sys: 228 Âµs, total: 460 Âµs\n",
      "Wall time: 280 Âµs\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "print f1(s0_dep_tk,s1_dep_tk,dep_prec,dep_rec)[2]\n",
    "print f1(s0_dep_tk,s2_dep_tk,dep_prec,dep_rec)[2]\n",
    "print f1(s0_dep_lm,s1_dep_lm,dep_prec,dep_rec)[2]\n",
    "print f1(s0_dep_lm,s2_dep_lm,dep_prec,dep_rec)[2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### E. Tree Edit Distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from zss import simple_distance, Node\n",
    "    # use zss.distance if dynamic tree modification is needed. \n",
    "    #  cf. zss api: pythonhosted.org/zss/."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def make_tree(token, lemmatized):\n",
    "    \n",
    "    node = Node(token.lemma_) if lemmatized else Node(token.orth_)\n",
    "    for child in token.children:\n",
    "        node.addkid(make_tree(child, lemmatized)) \n",
    "    return node"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def tree_edit_dist(root_s1, root_s2, lemmatized=False):\n",
    "    \n",
    "    return simple_distance(make_tree(root_s1, lemmatized),\n",
    "                           make_tree(root_s2, lemmatized))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "s0_root_lm = X_train[0]['s1_root_lm']\n",
    "s1_root_lm = X_train[0]['s2_root_lm']\n",
    "s2_root_lm = X_train[1]['s1_root_lm']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15\n",
      "21\n",
      "15\n",
      "21\n",
      "CPU times: user 30.6 ms, sys: 7.67 ms, total: 38.3 ms\n",
      "Wall time: 32.9 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "print tree_edit_dist(s0_root_lm,s1_root_lm)\n",
    "print tree_edit_dist(s0_root_lm,s2_root_lm)\n",
    "print tree_edit_dist(s0_root_lm,s1_root_lm, lemmatized=True)\n",
    "print tree_edit_dist(s0_root_lm,s2_root_lm, lemmatized=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "s0_root_tk = X_train[0]['s1_root_tk']\n",
    "s1_root_tk = X_train[0]['s2_root_tk']\n",
    "s2_root_tk = X_train[1]['s1_root_tk']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13\n",
      "21\n",
      "CPU times: user 17.8 ms, sys: 7.07 ms, total: 24.8 ms\n",
      "Wall time: 19.7 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "print tree_edit_dist(s0_root_tk,s1_root_tk)\n",
    "print tree_edit_dist(s0_root_tk,s2_root_tk)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### F. Sentence Lengths"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* \"... the difference in length of two sentences ... measured in words by subtracting one length from the other.\" (cf. Wan et al. 2006:134)\n",
    "* \"... this difference could be a negative or positive integer ... an absolute variant was used.\" (cf. ibid.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def sent_len_diffs(s1, s2):\n",
    "    \n",
    "    diff = len(s1)-len(s2)\n",
    "    \n",
    "    return diff, abs(diff)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(-1, 1)\n",
      "(0, 0)\n"
     ]
    }
   ],
   "source": [
    "print sent_len_diffs(s0,s1)\n",
    "print sent_len_diffs(s0,s2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## IIb: Featurization Function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Features (22 in total)**:\n",
    "\n",
    "* Unigram Prec/Rec + lemmatized variant: 4\n",
    "* Bleu Prec/Rec + lemmatized variant: 4\n",
    "* Dependency Prec/Rec + lemmatized variant: 4\n",
    "* F1 Unigram, Bleu, Dependency + lemmatized variant: 6\n",
    "* Tree Edit Distance + lemmatized variant: 2\n",
    "* Sentence Lengths: 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class Cache(object):\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.parse = {}\n",
    "        self.token_s = {}\n",
    "        self.token_lm = {}\n",
    "        self.dep_lm = {}\n",
    "        self.dep_tk = {}\n",
    "        self.root = {}\n",
    "       \n",
    "    def get_parse(self, s):\n",
    "        if s not in self.parse:\n",
    "            self.parse[s] = parser(s)\n",
    "        return self.parse[s]\n",
    "\n",
    "    def get_token_s(self, s):\n",
    "        if s not in self.token_s:\n",
    "            self.token_s[s] = [token.orth_ for token in self.get_parse(s)]\n",
    "        return self.token_s[s]\n",
    "   \n",
    "    def get_token_lm(self, s):\n",
    "        if s not in self.token_lm:\n",
    "            self.token_lm[s] = [token.lemma_ for token in self.get_parse(s)]\n",
    "        return self.token_lm[s]\n",
    "   \n",
    "    def get_dep_lm(self, s):\n",
    "        if s not in self.dep_lm:\n",
    "            self.dep_lm[s] = dep_lemmas(self.get_parse(s))\n",
    "        return self.dep_lm[s]\n",
    "   \n",
    "    def get_dep_tk(self, s):\n",
    "        if s not in self.dep_tk:\n",
    "            self.dep_tk[s] = dep_tokens(self.get_parse(s))\n",
    "        return self.dep_tk[s]\n",
    "   \n",
    "    def get_root(self, s):\n",
    "        if s not in self.root:\n",
    "            self.root[s] = get_root(self.get_parse(s))\n",
    "        return self.root[s]\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "CACHE = Cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def featurize_new(s1, s2): \n",
    "    # featurize a new input.\n",
    "    # s1 and s2 are strings\n",
    "\n",
    "    s1_s = CACHE.get_token_s(s1)\n",
    "    s2_s = CACHE.get_token_s(s2)    \n",
    "    s1_lm = CACHE.get_token_lm(s1)\n",
    "    s2_lm = CACHE.get_token_lm(s2)\n",
    "    s1_dep_lm = CACHE.get_dep_lm(s1)\n",
    "    s2_dep_lm = CACHE.get_dep_lm(s2)\n",
    "    s1_dep_tk = CACHE.get_dep_tk(s1)\n",
    "    s2_dep_tk = CACHE.get_dep_tk(s2)    \n",
    "    s1_root = CACHE.get_root(s1)\n",
    "    s2_root = CACHE.get_root(s2)\n",
    "\n",
    "    return list(f1(s1_s,s2_s,uni_prec,uni_rec)+f1(s1_lm,s2_lm,uni_prec,uni_rec)+\\\n",
    "                f1(s1_s,s2_s,bleu_prec,bleu_rec)+f1(s1_lm,s2_lm,bleu_prec,bleu_rec)+\\\n",
    "                f1(s1_dep_tk,s2_dep_tk,dep_prec,dep_rec)+f1(s1_dep_lm,s2_dep_lm,dep_prec,dep_rec)+\\\n",
    "                (tree_edit_dist(s1_root,s2_root),)+(tree_edit_dist(s1_root,s2_root,lemmatized=True),)+\\\n",
    "                sent_len_diffs(s1_s, s2_s))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Amrozi accused his brother , whom he called the witness , of deliberately distorting his evidence\n",
      "Referring to him as only the witness , Amrozi accused his brother of deliberately distorting his evidence\n",
      "Yucaipa owned Dominick 's before selling the chain to Safeway in 1998 for $ 2.5 billion\n"
     ]
    }
   ],
   "source": [
    "s0_asnew, s1_asnew, s2_asnew = ' '.join(s0), ' '.join(s1), ' '.join(s2)\n",
    "print s0_asnew\n",
    "print s1_asnew\n",
    "print s2_asnew"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.6875, 0.6470588235294118, 0.6666666666666667, 0.6875, 0.6470588235294118, 0.6666666666666667, 0.5, 0.4924790605054523, 0.49621103366618263, 0.5, 0.4924790605054523, 0.49621103366618263, 0.5714285714285714, 0.5, 0.5333333333333333, 0.5714285714285714, 0.5, 0.5333333333333333, 13, 13, -1, 1]\n",
      "\n",
      "[0.0625, 0.0625, 0.0625, 0.0625, 0.0625, 0.0625, 0, 0, 0, 0, 0, 0, 0.0, 0.0, 0, 0.0, 0.0, 0, 21, 21, 0, 0]\n",
      "CPU times: user 44.3 ms, sys: 6.86 ms, total: 51.1 ms\n",
      "Wall time: 46.1 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "print featurize_new(s0_asnew,s1_asnew)\n",
    "print \n",
    "print featurize_new(s0_asnew,s2_asnew)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## IV. Paraphrase Classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### A. Featurizing Training/Test from MSR\n",
    "\n",
    "* \"... the training set contains 2753 true paraphrase pairs and 1323 false paraphrase pairs; ... the test set contains 1147 and 578 pairs, respectively.\" (cf. Ji & Eisenstein 2013:893)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['s1_dep_lm', 's1_lm', 's2_dep_lm', 's2', 's1', 's2_root', 's1_dep_tk', 's1_root', 's1_id', 's2_dep_tk', 's2_id', 's2_lm']\n"
     ]
    }
   ],
   "source": [
    "print X_train[0].keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 420,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def featurize_set(X, Y):\n",
    "    \n",
    "    X_list, Y_list = [], []\n",
    "    \n",
    "    for i in xrange(len(X)):\n",
    "\n",
    "        uni_tk_prec, uni_tk_rec, uni_tk_f1 = f1_unigram(X[i]['s1'], X[i]['s2'])\n",
    "        uni_lm_prec, uni_lm_rec, uni_lm_f1 = f1_unigram(X[i]['s1_lm'], X[i]['s2_lm'])\n",
    "        bleu_tk_prec, bleu_tk_rec, bleu_tk_f1 = f1_bleu(X[i]['s1'], X[i]['s2'])\n",
    "        bleu_lm_prec, bleu_lm_rec, bleu_lm_f1 = f1_bleu(X[i]['s1_lm'], X[i]['s2_lm'])\n",
    "        dep_tk_prec, dep_tk_rec, dep_tk_f1 = f1_dep(X[i]['s1_dep_tk'], X[i]['s2_dep_tk'])\n",
    "        dep_lm_prec, dep_lm_rec, dep_lm_f1 = f1_dep(X[i]['s1_dep_lm'], X[i]['s2_dep_lm'])\n",
    "        tree_tk_dist = tree_edit_dist(X[i]['s1_root'], X[i]['s2_root'])\n",
    "        tree_lm_dist = tree_edit_dist(X[i]['s1_root'], X[i]['s2_root'],lemmatized=True) \n",
    "        diff, abs_diff = sent_len_diffs(X[i]['s1'], X[i]['s2'])\n",
    "        X_list.append(\n",
    "            [uni_tk_prec, uni_tk_rec, uni_tk_f1,\n",
    "             uni_lm_prec, uni_lm_rec, uni_lm_f1,\n",
    "             bleu_tk_prec, bleu_tk_rec, bleu_tk_f1,\n",
    "             bleu_lm_prec, bleu_lm_rec, bleu_lm_f1,\n",
    "             dep_tk_prec, dep_tk_rec, dep_tk_f1,\n",
    "             dep_lm_prec, dep_lm_rec, dep_lm_f1,\n",
    "             tree_tk_dist, tree_lm_dist,\n",
    "             diff, abs_diff]\n",
    "        )\n",
    "        Y_list.append(Y[i])\n",
    "    \n",
    "    return X_list, Y_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 367,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1h 35min 22s, sys: 14.6 s, total: 1h 35min 36s\n",
      "Wall time: 1h 35min 39s\n"
     ]
    }
   ],
   "source": [
    "# %%time\n",
    "# X_train_fts, Y_train_fts = featurize_set(X_train, Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 368,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 38min 49s, sys: 4.84 s, total: 38min 54s\n",
      "Wall time: 38min 54s\n"
     ]
    }
   ],
   "source": [
    "# %%time\n",
    "# X_test_fts, Y_test_fts = featurize_set(X_test, Y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import cPickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data_path = \"/Users/jacobsw/Desktop/WORK/OJO_CODE/SENTENCE_SIMILARITIES/DATA/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 369,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# SAVED ON THE FIRST VERSION OF FEATURES\n",
    "# with open(data_path+'train1.p','wb') as f_train:\n",
    "#     cPickle.dump((X_train_fts,Y_train_fts), f_train)\n",
    "# with open(data_path+'test1.p','wb') as f_test:\n",
    "#     cPickle.dump((X_test_fts,Y_test_fts), f_test)\n",
    "\n",
    "# SAVED ON THE SECOND VERSION OF FEATURES\n",
    "# with open(data_path+'train2.p','wb') as f_train:\n",
    "#     cPickle.dump((X_train_fts,Y_train_fts), f_train)\n",
    "# with open(data_path+'test2.p','wb') as f_test:\n",
    "#     cPickle.dump((X_test_fts,Y_test_fts), f_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# DATA SAVED, ONLY NEED TO LOAD FROM FILE\n",
    "with open(data_path+'train1.p','rb') as f_train:\n",
    "    X_train_fts, Y_train_fts = cPickle.load(f_train)\n",
    "with open(data_path+'test1.p','rb') as f_test:\n",
    "    X_test_fts, Y_test_fts = cPickle.load(f_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### B. Logistic Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Fit with Defaults"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "lr = LogisticRegression()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
       "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
       "          verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr.fit(X_train_fts, Y_train_fts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y_true = Y_test_fts\n",
    "y_pred = lr.predict(X_test_fts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "73.1014492754\n"
     ]
    }
   ],
   "source": [
    "print (accuracy_score(y_true,y_pred)*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.62      0.50      0.56       578\n",
      "          1       0.77      0.85      0.81      1147\n",
      "\n",
      "avg / total       0.72      0.73      0.72      1725\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print classification_report(y_true,y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 393,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1])"
      ]
     },
     "execution_count": 393,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr.predict([X_test_fts[0]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 394,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.43215239,  0.56784761]])"
      ]
     },
     "execution_count": 394,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr.predict_proba([X_test_fts[0]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Grid Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 404,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.grid_search import GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 408,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "parameters = {\n",
    "    'C': (.5,1.,5.,10.,20.),\n",
    "    'max_iter': (50,100,200),\n",
    "    'penalty': ('l1','l2')\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 410,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 5min 18s, sys: 673 ms, total: 5min 19s\n",
      "Wall time: 5min 20s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "grd = GridSearchCV(LogisticRegression(),parameters,cv=5)\n",
    "grd.fit(X_train_fts,Y_train_fts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 415,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Score: 73.527969%\n",
      "Best Params: \n",
      "\tC: 10.0\n",
      "\tmax_iter: 200\n",
      "\tpenalty: 'l2'\n"
     ]
    }
   ],
   "source": [
    "print \"Best Score: %.6f%%\" % (grd.best_score_*100)\n",
    "print \"Best Params: \"\n",
    "best_params = grd.best_estimator_.get_params()\n",
    "for param_name in sorted(parameters.keys()):\n",
    "    print \"\\t%s: %r\" % (param_name, best_params[param_name])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Fit with Best"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 439,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=10.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=200, multi_class='ovr', n_jobs=1,\n",
       "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
       "          verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 439,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr = LogisticRegression(C=10.,max_iter=200,penalty='l2')\n",
    "lr.fit(X_train_fts, Y_train_fts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 440,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22\n",
      "[ 0.01036332  0.0406214  -0.04055824 -0.32283921 -0.30543069  0.66289029\n",
      "  0.65056561 -0.24493119 -0.21115104 -0.15354829 -0.10937086 -0.28815355\n",
      " -1.33465664 -0.68327822 -0.93370973  0.29397644  1.0149985   0.68062963\n",
      " -0.13821721  0.03671789 -0.06489293  0.01009204]\n"
     ]
    }
   ],
   "source": [
    "print len(lr.coef_[0]) # 22 params\n",
    "print lr.coef_[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 441,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "73.0434782609\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.62      0.51      0.56       578\n",
      "          1       0.77      0.84      0.81      1147\n",
      "\n",
      "avg / total       0.72      0.73      0.72      1725\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_true = Y_test_fts\n",
    "y_pred = lr.predict(X_test_fts)\n",
    "print (accuracy_score(y_true,y_pred)*100)\n",
    "print classification_report(y_true,y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### C. SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 469,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn import svm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 474,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "clf = svm.SVC(probability=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 475,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVC(C=1.0, cache_size=200, class_weight=None, coef0=0.0,\n",
       "  decision_function_shape=None, degree=3, gamma='auto', kernel='rbf',\n",
       "  max_iter=-1, probability=True, random_state=None, shrinking=True,\n",
       "  tol=0.001, verbose=False)"
      ]
     },
     "execution_count": 475,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.fit(X_train_fts, Y_train_fts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 476,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y_true = Y_test_fts\n",
    "y_pred = clf.predict(X_test_fts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 477,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "69.1594202899\n"
     ]
    }
   ],
   "source": [
    "print (accuracy_score(y_true,y_pred)*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 478,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.58      0.29      0.39       578\n",
      "          1       0.71      0.89      0.79      1147\n",
      "\n",
      "avg / total       0.67      0.69      0.66      1725\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print classification_report(y_true,y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 401,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1])"
      ]
     },
     "execution_count": 401,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.predict([X_test_fts[0]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 402,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.28366846,  0.71633154]])"
      ]
     },
     "execution_count": 402,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.predict_proba([X_test_fts[0]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 484,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "parameters = {\n",
    "    'C': (.5,1.,5.,10.,20.),\n",
    "    'degree': (2,3,4,5),\n",
    "    'kernel': ('linear','poly','rbf','sigmoid'),\n",
    "    'shrinking': (True, False)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "grd = GridSearchCV(svm.SVC(),parameters,cv=5)\n",
    "grd.fit(X_train_fts,Y_train_fts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print \"Best Score: %.6f%%\" % (grd.best_score_*100)\n",
    "print \"Best Params: \"\n",
    "best_params = grd.best_estimator_.get_params()\n",
    "for param_name in sorted(parameters.keys()):\n",
    "    print \"\\t%s: %r\" % (param_name, best_params[param_name])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## V. Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ojo_sents = u'''\n",
    "What are the quality of schools in this neighborhood?\n",
    "What areas have the best schools?\n",
    "What are the crime statistics in this neighborhood?\n",
    "What are the number of registered sex offenders in this neighborhood?\n",
    "What is the walkability score in this neighborhood?\n",
    "Which neighborhoods have homes that are over 2500 sq ft. \n",
    "What neighborhoods have new construction\n",
    "Show me pictures of the neighborhood\n",
    "Show me pictures of homes in the neighborhood\n",
    "How bicycle friendly is this neighborhood?\n",
    "What is the median income of this neighborhood?\n",
    "What is the average demographics of this neighborhood? \n",
    "What is the poverty score of this neighborhood?\n",
    "What is the best day of the week to list my home?\n",
    "What is the best month to list a home like mine for the most money and shortest time?\n",
    "How much has my home appreciated?\n",
    "How has appreciation been in my neighborhood vs other neighborhoods?\n",
    "What has the average appreciation in my neighborhood been over the last x years?\n",
    "What has the average appreciation in my school district been over the last x years?\n",
    "What has the average appreciation on my street been over the last x years?\n",
    "Which neighborhoods are best for kids under 10\n",
    "Show me the nearest parks\n",
    "Show me the nearest pools\n",
    "Show me the nearest dog parks\n",
    "Show me the nearest urgent care / emergency room?\n",
    "Show me the nearest fire / police station?\n",
    "Show me the impact of railroad/trains\n",
    "How has appreciation been in this neighborhood vs other neighborhoods?\n",
    "What has the average appreciation in this neighborhood over the last x years?\n",
    "What has the average appreciation in this school district over the last x years?\n",
    "Where can I find a house that is a better fit for me for less money?\n",
    "What is the commute time for this neighborhood?\n",
    "Which neighborhoods have a commute time of less than 30min from [address]\n",
    "I want to live in a low traffic spot\n",
    "Show me diversity of neighborhood\n",
    "Show me historic natural disaster trends for this area\n",
    "Show me historic weather trends for this area\n",
    "Where can I find a house that is a better fit for me for less money?\n",
    "What confidence level does OJO have that I should list my home now?\n",
    "What confidence level does OJO have that I should buy a home right now?\n",
    "How much is my home worth?\n",
    "What confidence level does OJO have that I should buy a home right now?\n",
    "Show me district city government information\n",
    "Which street(s) in this neighborhood have the highest appreciation over x years?\n",
    "What is the expected appreciation for my home over the next x years?\n",
    "Which neighborhood in Austin is expected to appreciate the most over the next x years that have homes similar to what I'm interested in?\n",
    "What areas have mature trees?\n",
    "What areas have the most greenspace?\n",
    "What is the expected appreciation for homes in this area over the next x years?\n",
    "Which neighborhood in Austin is expected to appreciate the most over the next x years that have homes similar to what I'm interested in?\n",
    "How is this neighborhood impacted by traffic congestion and which time(s) of day?\n",
    "How fast will my home sell?\n",
    "Is this a pet friendly neighborhood?\n",
    "What are the utility costs in this neighborhood?\n",
    "I want to live in a tidy area\n",
    "I want a area where the homes are setback from the streeet\n",
    "Are there complete streets in this neighborhood (connecting sidewalks)?\n",
    "Green building score?\n",
    "Air quaiilty of city/neighborhood?\n",
    "Air quaility of home (VOCs, materials)\n",
    "Curbside waster services?\n",
    "Curbside recycling services?\n",
    "Curbside composting services?\n",
    "Average heating/cooling costs?\n",
    "Is sustainiable energy availalbe?\n",
    "Show me the impact of flight patterns\n",
    "What are the zoning breakdowns of this neighborhood? (section 8, residtential, mixed used, commercial, etc)?\n",
    "What is the estimated time to sell my home right now?\n",
    "How long does it take to sell a home in my neighborhood right now?\n",
    "How long does it take to sell a home on my street right now?\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def drop_question_mark(s):\n",
    "    return s[:-1] if s.endswith('?') else s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "ojo_sents = ojo_sents.split('\\n') # split into list of sent strings.\n",
    "ojo_sents = ojo_sents[1:len(ojo_sents)-1] # get rid of ''s in front and end.\n",
    "ojo_sents = list({drop_question_mark(sent) for sent in ojo_sents}) # get rid of question mark and duplicates.\n",
    "# ojo_sents = [sent.split() for sent in ojo_sents]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "u'Show me the impact of flight patterns'"
      ]
     },
     "execution_count": 142,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ojo_sents[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "q1 = u'are the schools in the neighborhood good'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from operator import itemgetter\n",
    "from heapq import nlargest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def top_k_sim(q, model, k=5):\n",
    "    # q: query sentence, a string\n",
    "    # model: classifier\n",
    "   \n",
    "    preds = []\n",
    "    X = [featurize_new(q, sent) for sent in ojo_sents]\n",
    "    probabilities = model.predict_proba(X)[:,1]\n",
    "    indices = probabilities.argsort()[::-1][:5]\n",
    "    print \"Predictions: \"\n",
    "    print\n",
    "    for j,i in enumerate(indices):\n",
    "        \n",
    "        prob = probabilities[i]\n",
    "        print '#%d Prediction: %s (prob=%.2f%%)' % (j,ojo_sents[i],prob)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predictions: \n",
      "\n",
      "#0 Prediction: What are the zoning breakdowns of this neighborhood? (section 8, residtential, mixed used, commercial, etc) (prob=0.74%)\n",
      "#1 Prediction: What are the crime statistics in this neighborhood (prob=0.58%)\n",
      "#2 Prediction: What are the utility costs in this neighborhood (prob=0.58%)\n",
      "#3 Prediction: What is the walkability score in this neighborhood (prob=0.57%)\n",
      "#4 Prediction: What are the number of registered sex offenders in this neighborhood (prob=0.55%)\n",
      "CPU times: user 385 ms, sys: 3.75 ms, total: 388 ms\n",
      "Wall time: 387 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "top_k_sim(q1, lr)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
