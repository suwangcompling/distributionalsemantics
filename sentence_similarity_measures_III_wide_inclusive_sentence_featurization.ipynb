{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Sentence Similarity Measures III: Wide-Inclusive Sentence Featurization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## 0. Contents\n",
    "\n",
    "* I. Corpora:\n",
    "    * MSR Paraphrase Corpus\n",
    "    * Brown\n",
    "* II. Discriminativity Weighting (Brown, SpaCy lemmatization)\n",
    "* III. Featurization:\n",
    "    * Features:\n",
    "        * Unigram Prec/Rec (Wan et al. 2006) \n",
    "        * Bleu Prec/Rec (Papineni et al. 2002)\n",
    "        * Dependency Prec/Rec (Wan et al. 2006; Moll$\\acute{a}$ 2003; Hovy et al. 2015)\n",
    "        * F1 for Unigram, Bleu & Dependency\n",
    "        * Tree Edit Distance (Zhang & Sasha Algorithm)\n",
    "        * Sentence Lengths (Wan et al. 2006)\n",
    "    * Featurization Function\n",
    "* IV. Paraphrase Classifier:\n",
    "    * Training: MSR Paraphrase Corpus\n",
    "    * Classifier Types:\n",
    "        * Logistic\n",
    "        * SVM\n",
    "* V. Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## I. Corpora"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from nltk.corpus import brown\n",
    "from spacy.en import English\n",
    "from collections import defaultdict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "parser = English()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Load MSR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_path = \"/Users/jacobsw/Desktop/WORK/OJO_CODE/SENTENCE_SIMILARITIES/CORPORA/paraphrase/msr_paraphrase_train.txt\"\n",
    "test_path = \"/Users/jacobsw/Desktop/WORK/OJO_CODE/SENTENCE_SIMILARITIES/CORPORA/paraphrase/msr_paraphrase_test.txt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>﻿Quality</th>\n",
       "      <th>#1 ID</th>\n",
       "      <th>#2 ID</th>\n",
       "      <th>#1 String</th>\n",
       "      <th>#2 String</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>702876</td>\n",
       "      <td>702977</td>\n",
       "      <td>Amrozi accused his brother, whom he called the...</td>\n",
       "      <td>Referring to him as only the witness, Amrozi a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>2108705</td>\n",
       "      <td>2108831</td>\n",
       "      <td>Yucaipa owned Dominick's before selling the ch...</td>\n",
       "      <td>Yucaipa bought Dominick's in 1995 for $693 mil...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>1330381</td>\n",
       "      <td>1330521</td>\n",
       "      <td>They had published an advertisement on the Int...</td>\n",
       "      <td>On June 10, the ship's owners had published an...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>3344667</td>\n",
       "      <td>3344648</td>\n",
       "      <td>Around 0335 GMT, Tab shares were up 19 cents, ...</td>\n",
       "      <td>Tab shares jumped 20 cents, or 4.6%, to set a ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>1236820</td>\n",
       "      <td>1236712</td>\n",
       "      <td>The stock rose $2.11, or about 11 percent, to ...</td>\n",
       "      <td>PG&amp;E Corp. shares jumped $1.63 or 8 percent to...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   ﻿Quality    #1 ID    #2 ID  \\\n",
       "0         1   702876   702977   \n",
       "1         0  2108705  2108831   \n",
       "2         1  1330381  1330521   \n",
       "3         0  3344667  3344648   \n",
       "4         1  1236820  1236712   \n",
       "\n",
       "                                           #1 String  \\\n",
       "0  Amrozi accused his brother, whom he called the...   \n",
       "1  Yucaipa owned Dominick's before selling the ch...   \n",
       "2  They had published an advertisement on the Int...   \n",
       "3  Around 0335 GMT, Tab shares were up 19 cents, ...   \n",
       "4  The stock rose $2.11, or about 11 percent, to ...   \n",
       "\n",
       "                                           #2 String  \n",
       "0  Referring to him as only the witness, Amrozi a...  \n",
       "1  Yucaipa bought Dominick's in 1995 for $693 mil...  \n",
       "2  On June 10, the ship's owners had published an...  \n",
       "3  Tab shares jumped 20 cents, or 4.6%, to set a ...  \n",
       "4  PG&E Corp. shares jumped $1.63 or 8 percent to...  "
      ]
     },
     "execution_count": 234,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train = pd.read_csv(train_path, delimiter='\\t')\n",
    "df_test = pd.read_csv(test_path, delimiter='\\t')\n",
    "df_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4076, 5)\n",
      "(1725, 5)\n"
     ]
    }
   ],
   "source": [
    "print df_train.shape\n",
    "print df_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 268,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "﻿Quality                                                     1\n",
       "#1 ID                                                   702876\n",
       "#2 ID                                                   702977\n",
       "#1 String    Amrozi accused his brother, whom he called the...\n",
       "#2 String    Referring to him as only the witness, Amrozi a...\n",
       "Name: 0, dtype: object"
      ]
     },
     "execution_count": 268,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.ix[0] # NB: index Quality is actually weirdly '﻿Quality'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Amrozi accused his brother, whom he called the witness, of deliberately distorting his evidence.'"
      ]
     },
     "execution_count": 252,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.ix[0]['#1 String']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Make Train/Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 614,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from zss import Node # for tree edit distance later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 562,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dep_lemmas = lambda parsed_s: {(token.head.lemma_,token.lemma_) for token in parsed_s\n",
    "                              if token.head.lemma_!=token.lemma_} # eliminte (v, ROOT, v) cases\n",
    "dep_tokens = lambda parsed_s: {(token.head.orth_,token.orth_) for token in parsed_s\n",
    "                              if token.head.lemma_!=token.lemma_} "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 617,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "get_root_lm = lambda parsed_s: Node([token.lemma_ for token in parsed_s if token.dep_=='ROOT'][0])\n",
    "get_root_tk = lambda parsed_s: Node([token.orth_ for token in parsed_s if token.dep_=='ROOT'][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 563,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X_train, X_test = defaultdict(lambda x: defaultdict(list)), defaultdict(lambda x: defaultdict(list))\n",
    "Y_train, Y_test = defaultdict(int), defaultdict(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 618,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def parse_msr(df, indexer):\n",
    "    \n",
    "    X_dic, Y_dic = defaultdict(lambda x: defaultdict(list)), \\\n",
    "                   defaultdict(lambda x: defaultdict(list))\n",
    "    \n",
    "    for i in indexer:\n",
    "        entry_dic = defaultdict(list)\n",
    "        s1, s2 = unicode(df.ix[i]['#1 String'].decode('utf-8','ignore')), \\\n",
    "                 unicode(df.ix[i]['#2 String'].decode('utf-8','ignore'))\n",
    "        parsed_s1, parsed_s2 = parser(s1), parser(s2)\n",
    "        entry_dic['s1'] = [token.orth_ for token in parsed_s1]\n",
    "        entry_dic['s2'] = [token.orth_ for token in parsed_s2]\n",
    "        entry_dic['s1_lm'] = [token.lemma_ for token in parsed_s1]\n",
    "        entry_dic['s2_lm'] = [token.lemma_ for token in parsed_s2]\n",
    "        entry_dic['s1_dep_lm'] = dep_lemmas(parsed_s1) # for dep lemma features.\n",
    "        entry_dic['s2_dep_lm'] = dep_lemmas(parsed_s2)\n",
    "        entry_dic['s1_dep_tk'] = dep_tokens(parsed_s1) # for dep token features.\n",
    "        entry_dic['s2_dep_tk'] = dep_tokens(parsed_s2)  \n",
    "        entry_dic['s1_root_lm'] = get_root_lm(parsed_s1)\n",
    "        entry_dic['s2_root_lm'] = get_root_lm(parsed_s2)\n",
    "        entry_dic['s1_root_tk'] = get_root_tk(parsed_s1)\n",
    "        entry_dic['s2_root_tk'] = get_root_tk(parsed_s2)\n",
    "        entry_dic['s1_id'] = df.ix[i]['#1 ID'] # for error analysis later.\n",
    "        entry_dic['s2_id'] = df.ix[i]['#2 ID']\n",
    "        X_dic[i] = entry_dic\n",
    "        Y_dic[i] = df.ix[i]['﻿Quality']\n",
    "    \n",
    "    return X_dic, Y_dic\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 619,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 18.7 s, sys: 204 ms, total: 18.9 s\n",
      "Wall time: 19 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "X_train, Y_train = parse_msr(df_train, df_train.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 620,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 7.61 s, sys: 21.9 ms, total: 7.64 s\n",
      "Wall time: 7.65 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "X_test, Y_test = parse_msr(df_test, df_test.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 621,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sentence 1:  [u'Amrozi', u'accused', u'his', u'brother', u',', u'whom', u'he', u'called', u'the', u'witness', u',', u'of', u'deliberately', u'distorting', u'his', u'evidence', u'.']\n",
      "\n",
      "sentence 2:  [u'Referring', u'to', u'him', u'as', u'only', u'the', u'witness', u',', u'Amrozi', u'accused', u'his', u'brother', u'of', u'deliberately', u'distorting', u'his', u'evidence', u'.']\n",
      "\n",
      "paraphrase label:  1\n"
     ]
    }
   ],
   "source": [
    "print 'sentence 1: ', X_train[0]['s1']; print\n",
    "print 'sentence 2: ', X_train[0]['s2']; print\n",
    "print 'paraphrase label: ', Y_train[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Load Brown"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def parse_brown():\n",
    "    \n",
    "    sents = brown.sents()\n",
    "    parsed_sents = [parser(' '.join(sent)) for sent in sents]\n",
    "    lemma_words = [token.lemma_ for parsed_sent in parsed_sents for token in parsed_sent]\n",
    "    \n",
    "    return lemma_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1min 38s, sys: 770 ms, total: 1min 39s\n",
      "Wall time: 1min 39s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "brown_words = parse_brown()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1188973"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "N = len(brown_words)\n",
    "N"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## I. Discriminativity Weighting (IDF)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Math**\n",
    "\n",
    "* $IDF(w) = log\\frac{N}{df_w}$, where $N$ is the number of words in a corpus; $df_w$ is word $w$'s frequency in the corpus."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 496,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from __future__ import division"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 497,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "log = lambda x: np.log(x) if x>0 else 0 \n",
    "    # intuitively N > word_count(w) for any w,\n",
    "    #  therefore we cannot let idf(w) be negative\n",
    "    #  even when word_count(w) = 0 for w.\n",
    "div = lambda x,y: x/y if y!=0 else 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 498,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def idf(w):\n",
    "    \n",
    "    return log(div(N,brown_words.count(w)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 499,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'the':  2.83230709\n",
      "'discriminate':  12.0426903182\n"
     ]
    }
   ],
   "source": [
    "print \"'the': \", idf('the')\n",
    "print \"'discriminate': \", idf('discriminate')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## IIa. Features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### A.  Unigram Prec/Rec"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Math**\n",
    "\n",
    "* $Uni\\_Prec(s_1,s_2) = \\frac{word\\_overlap(s_1,s_2)\\cdot \\left(\\sum_{w\\in s_1\\cap s_2}log\\frac{N}{df_w}\\right)}{word\\_count(s_1)}$ (cf. Wan et al. 2006:133, weighted by $IDF$)\n",
    "\n",
    "\n",
    "* $Uni\\_Rec(s_1,s_2) = \\frac{word\\_overlap(s_1,s_2)\\cdot \\left(\\sum_{w\\in s_1\\cap s_2}log\\frac{N}{df_w}\\right)}{word\\_count(s_2)}$ (cf. ibid.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 500,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "intersection = lambda s1,s2: set(s1).intersection(set(s2))\n",
    "word_overlap = lambda s1,s2: len(intersection(s1,s2))\n",
    "lemmatize = lambda s: [token.lemma_ for token in parser(' '.join(s))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 501,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def uni_prec(s1, s2): # s1,s2 assumed to be lists of words (lemmas or tokens)\n",
    "\n",
    "    return div(word_overlap(s1,s2) * \\\n",
    "               sum(idf(w) for w in intersection(s1,s2)),\n",
    "               len(s1))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 504,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def uni_rec(s1, s2):   \n",
    "    \n",
    "    return div(word_overlap(s1,s2) * \\\n",
    "               sum(idf(w) for w in intersection(s1,s2)),\n",
    "               len(s2))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 569,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "s0 = X_train[0]['s1']\n",
    "s1 = X_train[0]['s2'] # known to be the paraphrase of q\n",
    "s2 = X_train[1]['s1'] # known to not be the paraphrase of q\n",
    "s0_lm = X_train[0]['s1_lm']\n",
    "s1_lm = X_train[0]['s2_lm']\n",
    "s2_lm = X_train[1]['s1_lm']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 570,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "39.3330201597\n",
      "0.706130559219\n",
      "54.5317127116\n",
      "0.706130559219\n",
      "CPU times: user 799 ms, sys: 2.96 ms, total: 802 ms\n",
      "Wall time: 804 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "print uni_prec(s0,s1)\n",
    "print uni_prec(s0,s2)\n",
    "print uni_prec(s0_lm,s1_lm)\n",
    "print uni_prec(s0_lm,s2_lm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 571,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "37.1478523731\n",
      "0.706130559219\n",
      "51.5021731165\n",
      "0.706130559219\n",
      "CPU times: user 801 ms, sys: 3.91 ms, total: 805 ms\n",
      "Wall time: 808 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "print uni_rec(s0,s1)\n",
    "print uni_rec(s0,s2)\n",
    "print uni_rec(s0_lm,s1_lm)\n",
    "print uni_rec(s0_lm,s2_lm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### B. BLEU Prec/Rec"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**NB** (cf. Wan et al. 2006:133)\n",
    "\n",
    "* \"... Bleu metric uses the geometric average of unigram, bigram and trigram precision scores.\"\n",
    "* \"... by reversing [two sentences], ... a recall version of Bleu is obtained.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 572,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from nltk import bleu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 573,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def bleu_prec(s1, s2, lemmatized=False): # s1 as the 'hypothesis'\n",
    "\n",
    "    return bleu(s2,s1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 574,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def bleu_rec(s1, s2, lemmatized=False): # s2 as the 'hypothesis' \n",
    "    \n",
    "    return bleu(s1,s2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 575,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.585659602743\n",
      "0.492479060505\n",
      "0.585659602743\n",
      "0.492479060505\n",
      "CPU times: user 8.07 ms, sys: 2.98 ms, total: 11 ms\n",
      "Wall time: 8.78 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "print bleu_prec(s0,s1)\n",
    "print bleu_prec(s0,s2)\n",
    "print bleu_prec(s0_lm,s1_lm)\n",
    "print bleu_prec(s0_lm,s2_lm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 576,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.57735026919\n",
      "0.492479060505\n",
      "0.57735026919\n",
      "0.492479060505\n",
      "CPU times: user 7.5 ms, sys: 3.31 ms, total: 10.8 ms\n",
      "Wall time: 8.4 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "print bleu_rec(s0,s1)\n",
    "print bleu_rec(s0,s2)\n",
    "print bleu_rec(s0_lm,s1_lm)\n",
    "print bleu_rec(s0_lm,s2_lm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### C. Dependency Prec/Rec"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Math**\n",
    "\n",
    "* $Dep\\_Prec(s_1,s_2) = \\frac{|dep\\_pair(s_1)|\\cap|dep\\_pair(s_2)|}{|dep\\_pair(s_1)|}$ (cf. Wan et al. 2006:134)\n",
    "\n",
    "\n",
    "* $Dep\\_Rec(s_1,s_2) = \\frac{|dep\\_pair(s_1)|\\cap|dep\\_pair(s_2)|}{|dep\\_pair(s_2)|}$ (cf. ibid.)\n",
    "\n",
    "**NB**: $relation$ in the reference confuses *dependency pair* with *dependency relation*. $relation$ refers to \"... a pair of words in a parent-child relationship within the dependency tree, referred to as head-modifier relationship. ... we ignore the label of the relationships which indicates the semantic role\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 577,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def dep_prec(dep_pairs_s1, dep_pairs_s2):\n",
    "    \n",
    "    return div(len(dep_pairs_s1.intersection(dep_pairs_s2)),\n",
    "               len(dep_pairs_s1))\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 578,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def dep_rec(dep_pairs_s1, dep_pairs_s2):\n",
    "    \n",
    "    return div(len(dep_pairs_s1.intersection(dep_pairs_s2)),\n",
    "               len(dep_pairs_s2))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 579,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "s0_dep_tk = X_train[0]['s1_dep_tk']\n",
    "s1_dep_tk = X_train[0]['s2_dep_tk']\n",
    "s2_dep_tk = X_train[1]['s1_dep_tk']\n",
    "s0_dep_lm = X_train[0]['s1_dep_lm']\n",
    "s1_dep_lm = X_train[0]['s2_dep_lm']\n",
    "s2_dep_lm = X_train[1]['s1_dep_lm']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 580,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6\n",
      "0.0\n",
      "0.6\n",
      "0.0\n",
      "CPU times: user 290 µs, sys: 344 µs, total: 634 µs\n",
      "Wall time: 294 µs\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "print dep_prec(s0_dep_tk,s1_dep_tk)\n",
    "print dep_prec(s0_dep_tk,s2_dep_tk)\n",
    "print dep_prec(s0_dep_lm,s1_dep_lm)\n",
    "print dep_prec(s0_dep_lm,s2_dep_lm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 581,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6\n",
      "0.0\n",
      "0.6\n",
      "0.0\n",
      "CPU times: user 201 µs, sys: 66 µs, total: 267 µs\n",
      "Wall time: 211 µs\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "print dep_prec(s0_dep_tk,s1_dep_tk)\n",
    "print dep_prec(s0_dep_tk,s2_dep_tk)\n",
    "print dep_prec(s0_dep_lm,s1_dep_lm)\n",
    "print dep_prec(s0_dep_lm,s2_dep_lm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### D. F1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Math**\n",
    "\n",
    "* $F1 = 2\\cdot\\frac{prec\\cdot rec}{prec + rec}$ (cf. https://en.wikipedia.org/wiki/F1_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 582,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def f1_unigram(s1, s2):\n",
    "    \n",
    "    prec, rec = uni_prec(s1,s2), uni_rec(s1,s2)\n",
    "    \n",
    "    return prec, rec, 2*div(prec*rec,prec+rec) # so later we only do uni_prec/rec once!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 583,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def f1_bleu(s1, s2):\n",
    "    \n",
    "    prec, rec = bleu_prec(s1,s2), bleu_rec(s1,s2)\n",
    "    \n",
    "    return prec, rec, 2*div(prec*rec,prec+rec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 584,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def f1_dep(dep_pairs_s1, dep_pairs_s2):\n",
    "   \n",
    "    prec, rec = dep_prec(dep_pairs_s1,dep_pairs_s2), \\\n",
    "                dep_rec(dep_pairs_s1,dep_pairs_s2)\n",
    "    \n",
    "    return prec, rec, 2*div(prec*rec,prec+rec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 585,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "38.2092195838\n",
      "0.706130559219\n",
      "52.973663777\n",
      "0.706130559219\n",
      "CPU times: user 1.64 s, sys: 9.47 ms, total: 1.65 s\n",
      "Wall time: 1.66 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "print f1_unigram(s0,s1)[2]\n",
    "print f1_unigram(s0,s2)[2]\n",
    "print f1_unigram(s0_lm,s1_lm)[2]\n",
    "print f1_unigram(s0_lm,s2_lm)[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 586,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.581475252201\n",
      "0.492479060505\n",
      "0.581475252201\n",
      "0.492479060505\n",
      "CPU times: user 14.2 ms, sys: 3.73 ms, total: 17.9 ms\n",
      "Wall time: 15 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "print f1_bleu(s0,s1)[2]\n",
    "print f1_bleu(s0,s2)[2]\n",
    "print f1_bleu(s0_lm,s1_lm)[2]\n",
    "print f1_bleu(s0_lm,s2_lm)[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 587,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5625\n",
      "0\n",
      "0.5625\n",
      "0\n",
      "CPU times: user 207 µs, sys: 165 µs, total: 372 µs\n",
      "Wall time: 215 µs\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "print f1_dep(s0_dep_tk,s1_dep_tk)[2]\n",
    "print f1_dep(s0_dep_tk,s2_dep_tk)[2]\n",
    "print f1_dep(s0_dep_lm,s1_dep_lm)[2]\n",
    "print f1_dep(s0_dep_lm,s2_dep_lm)[2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### E. Tree Edit Distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 626,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from zss import simple_distance\n",
    "    # use zss.distance if dynamic tree modification is needed. \n",
    "    #  cf. zss api: pythonhosted.org/zss/."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 631,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def make_zss_tree(node, dep_pairs):\n",
    "    \n",
    "    for dep_pair in dep_pairs:\n",
    "        if node.label==dep_pair[0]:\n",
    "            kid = make_zss_tree(Node(dep_pair[1]), dep_pairs)\n",
    "            node.addkid(kid)\n",
    "    \n",
    "    return node"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 632,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def tree_edit_dist(root_s1, root_s2, dep_pairs_s1, dep_pairs_s2):\n",
    "   \n",
    "    tree_s1, tree_s2 = make_zss_tree(root_s1,dep_pairs_s1), \\\n",
    "                       make_zss_tree(root_s2,dep_pairs_s2)\n",
    "    \n",
    "    return simple_distance(tree_s1, tree_s2)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 633,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "s0_root_lm = X_train[0]['s1_root_lm']\n",
    "s1_root_lm = X_train[0]['s2_root_lm']\n",
    "s2_root_lm = X_train[1]['s1_root_lm']\n",
    "s0_root_tk = X_train[0]['s1_root_tk']\n",
    "s1_root_tk = X_train[0]['s2_root_tk']\n",
    "s2_root_tk = X_train[1]['s1_root_tk']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 634,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "57\n",
      "96\n",
      "CPU times: user 259 ms, sys: 4.29 ms, total: 264 ms\n",
      "Wall time: 262 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "print tree_edit_dist(s0_root_tk,s1_root_tk,s0_dep_tk,s1_dep_tk)\n",
    "print tree_edit_dist(s0_root_tk,s2_root_tk,s0_dep_tk,s2_dep_tk)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 635,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17\n",
      "33\n",
      "CPU times: user 24.5 ms, sys: 2.84 ms, total: 27.4 ms\n",
      "Wall time: 25.2 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "print tree_edit_dist(s0_root_lm,s1_root_lm,s0_dep_lm,s1_dep_lm)\n",
    "print tree_edit_dist(s0_root_lm,s2_root_lm,s0_dep_lm,s2_dep_lm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Step-by-Step Walkthrough of Tree Building"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**a. Parse Sample Sents**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 374,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "set([(u'mac', u'a'), (u'eat', u'mac'), (u'mac', u'big'), (u'eat', u'i')])\n",
      "set([(u'mac', u'a'), (u'eat', u'mac'), (u'eat', u'i'), (u'mac', u'small')])\n"
     ]
    }
   ],
   "source": [
    "sample1 = u'i ate a big mac'\n",
    "sample2 = u'i ate a small mac'\n",
    "parsed_sample1 = parser(sample1)\n",
    "parsed_sample2 = parser(sample2)\n",
    "print dep_pairs(parsed_sample1)\n",
    "print dep_pairs(parsed_sample2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 375,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "eat nsubj i\n",
      "eat ROOT eat\n",
      "mac det a\n",
      "mac amod big\n",
      "eat dobj mac\n"
     ]
    }
   ],
   "source": [
    "for token in parsed_sample1:\n",
    "    print token.head.lemma_,token.dep_,token.lemma_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**b. Make Tree & Check for Samples**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 376,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "test1 = make_zss_tree(Node('eat'),dep_pairs(parsed_sample1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 377,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2:eat\n",
      "2:mac\n",
      "0:a\n",
      "0:big\n",
      "0:i\n"
     ]
    }
   ],
   "source": [
    "print test1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 378,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[<zss.simple_tree.Node object at 0x116adf4d0 mac>, <zss.simple_tree.Node object at 0x18287b950 i>]\n"
     ]
    }
   ],
   "source": [
    "print test1.get_children(test1)\n",
    "mac, i = test.get_children(test1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 379,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[<zss.simple_tree.Node object at 0x11a661f10 a>, <zss.simple_tree.Node object at 0x18287b990 big>]\n"
     ]
    }
   ],
   "source": [
    "print mac.get_children(mac)\n",
    "a, big = mac.get_children(mac)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 380,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n"
     ]
    }
   ],
   "source": [
    "print i.get_children(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 381,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n",
      "[]\n"
     ]
    }
   ],
   "source": [
    "print a.get_children(a)\n",
    "print big.get_children(big)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 382,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test2 = make_zss_tree(Node('eat'),dep_pairs(parsed_sample2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 383,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2:eat\n",
      "2:mac\n",
      "0:a\n",
      "0:small\n",
      "0:i\n"
     ]
    }
   ],
   "source": [
    "print test2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 384,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[<zss.simple_tree.Node object at 0x11a661c90 mac>, <zss.simple_tree.Node object at 0x18287bc90 i>]\n"
     ]
    }
   ],
   "source": [
    "print test2.get_children(test2)\n",
    "mac, i = test.get_children(test2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 385,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[<zss.simple_tree.Node object at 0x11a661c50 a>, <zss.simple_tree.Node object at 0x11a661c10 small>]\n"
     ]
    }
   ],
   "source": [
    "print mac.get_children(mac)\n",
    "a, small = mac.get_children(mac)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 386,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n"
     ]
    }
   ],
   "source": [
    "print i.get_children(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 387,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n",
      "[]\n"
     ]
    }
   ],
   "source": [
    "print a.get_children(a)\n",
    "print small.get_children(small)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**c. Compute Edit Distance**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 388,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 388,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "simple_distance(test1,test2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### F. Sentence Lengths"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* \"... the difference in length of two sentences ... measured in words by subtracting one length from the other.\" (cf. Wan et al. 2006:134)\n",
    "* \"... this difference could be a negative or positive integer ... an absolute variant was used.\" (cf. ibid.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 389,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def sent_len_diffs(s1, s2):\n",
    "    \n",
    "    diff = len(s1)-len(s2)\n",
    "    \n",
    "    return [diff, abs(diff)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 390,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-1, 1]\n",
      "[0, 0]\n"
     ]
    }
   ],
   "source": [
    "print sent_len_diffs(s0,s1)\n",
    "print sent_len_diffs(s0,s2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## IIb: Featurization Function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Features (22 in total)**:\n",
    "\n",
    "* Unigram Prec/Rec + lemmatized variant: 4\n",
    "* Bleu Prec/Rec + lemmatized variant: 4\n",
    "* Dependency Prec/Rec + lemmatized variant: 4\n",
    "* F1 Unigram, Bleu, Dependency + lemmatized variant: 6\n",
    "* Tree Edit Distance + lemmatized variant: 2\n",
    "* Sentence Lengths: 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 408,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 409,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def featurize(s1, s2): # s is a list of words.\n",
    "    \n",
    "    unigram_fts = [uni_prec(s1,s2),uni_rec(s1,s2),\n",
    "                   uni_prec(s1,s2,lemmatized=True),uni_rec(s1,s2,lemmatized=True)]\n",
    "    bleu_fts = [bleu_prec(s1,s2),bleu_rec(s1,s2),\n",
    "                bleu_prec(s1,s2,lemmatized=True),bleu_rec(s1,s2,lemmatized=True)]\n",
    "    dep_fts = [dep_prec(s1,s2),dep_rec(s1,s2),\n",
    "               dep_prec(s1,s2,lemmatized=True),dep_rec(s1,s2,lemmatized=True)]\n",
    "    f1_fts = [f1_unigram(s1,s2),f1_bleu(s1,s2),f1_dep(s1,s2),\n",
    "              f1_unigram(s1,s2,lemmatized=True),f1_bleu(s1,s2,lemmatized=True),f1_dep(s1,s2,lemmatized=True)]\n",
    "    tree_fts = [tree_edit_dist(s1,s2),\n",
    "                tree_edit_dist(s1,s2,lemmatized=True)]\n",
    "    len_fts = sent_len_diffs(s1,s2)\n",
    "                   \n",
    "    return np.asarray(unigram_fts+bleu_fts+dep_fts+f1_fts+tree_fts+len_fts)\n",
    "                   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 411,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 39.33302016  37.14785237  54.53171271  51.50217312   0.5856596\n",
      "   0.57735027   0.5856596    0.57735027   0.6          0.52941176   0.5625\n",
      "   0.52941176  38.20921958   0.58147525   0.5625      52.97366378\n",
      "   0.58147525   0.54545455  17.          10.          -1.           1.        ]\n",
      "CPU times: user 2.9 s, sys: 12.9 ms, total: 2.92 s\n",
      "Wall time: 2.93 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "print featurize(s0,s1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## IV. Paraphrase Classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### A. Featurizing Training/Test from MSR\n",
    "\n",
    "* \"... the training set contains 2753 true paraphrase pairs and 1323 false paraphrase pairs; ... the test set contains 1147 and 578 pairs, respectively.\" (cf. Ji & Eisenstein 2013:893)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 413,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "defaultdict(<type 'list'>, {'s2_id': 702977, 's2': [u'Referring', u'to', u'him', u'as', u'only', u'the', u'witness', u',', u'Amrozi', u'accused', u'his', u'brother', u'of', u'deliberately', u'distorting', u'his', u'evidence', u'.'], 's1': [u'Amrozi', u'accused', u'his', u'brother', u',', u'whom', u'he', u'called', u'the', u'witness', u',', u'of', u'deliberately', u'distorting', u'his', u'evidence', u'.'], 's1_id': 702876})\n"
     ]
    }
   ],
   "source": [
    "print X_train[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 470,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def featurize_set(X, Y):\n",
    "    \n",
    "    X_list, Y_list = [], []\n",
    "    for i in xrange(len(X)):\n",
    "        try:\n",
    "            X_list.append(featurize(X[i]['s1'],X[i]['s2']))\n",
    "            Y_list.append(Y[i])\n",
    "        except Exception:\n",
    "            print Exception\n",
    "            print 'idx: ', i\n",
    "    \n",
    "    return X_list, Y_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 465,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<type 'exceptions.Exception'>\n",
      "idx:  24\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-465-7c037e412117>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mget_ipython\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_cell_magic\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mu'time'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34mu''\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34mu'X_train_fts, Y_train_fts = featurize_set(X_train, Y_train)'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/Users/jacobsw/anaconda2/lib/python2.7/site-packages/IPython/core/interactiveshell.pyc\u001b[0m in \u001b[0;36mrun_cell_magic\u001b[0;34m(self, magic_name, line, cell)\u001b[0m\n\u001b[1;32m   2118\u001b[0m             \u001b[0mmagic_arg_s\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvar_expand\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mline\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstack_depth\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2119\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuiltin_trap\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2120\u001b[0;31m                 \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmagic_arg_s\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcell\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2121\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2122\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<decorator-gen-60>\u001b[0m in \u001b[0;36mtime\u001b[0;34m(self, line, cell, local_ns)\u001b[0m\n",
      "\u001b[0;32m/Users/jacobsw/anaconda2/lib/python2.7/site-packages/IPython/core/magic.pyc\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m(f, *a, **k)\u001b[0m\n\u001b[1;32m    191\u001b[0m     \u001b[0;31m# but it's overkill for just that one bit of state.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    192\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mmagic_deco\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 193\u001b[0;31m         \u001b[0mcall\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mlambda\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    194\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    195\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcallable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/jacobsw/anaconda2/lib/python2.7/site-packages/IPython/core/magics/execution.pyc\u001b[0m in \u001b[0;36mtime\u001b[0;34m(self, line, cell, local_ns)\u001b[0m\n\u001b[1;32m   1175\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1176\u001b[0m             \u001b[0mst\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclock2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1177\u001b[0;31m             \u001b[0;32mexec\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mglob\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlocal_ns\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1178\u001b[0m             \u001b[0mend\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclock2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1179\u001b[0m             \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<timed exec>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m<ipython-input-463-45bf99739acb>\u001b[0m in \u001b[0;36mfeaturize_set\u001b[0;34m(X, Y)\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mxrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m             \u001b[0mX_list\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeaturize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m's1'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m's2'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m             \u001b[0mY_list\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mY\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-409-9372cdbb42ce>\u001b[0m in \u001b[0;36mfeaturize\u001b[0;34m(s1, s2)\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     unigram_fts = [uni_prec(s1,s2),uni_rec(s1,s2),\n\u001b[0;32m----> 4\u001b[0;31m                    uni_prec(s1,s2,lemmatized=True),uni_rec(s1,s2,lemmatized=True)]\n\u001b[0m\u001b[1;32m      5\u001b[0m     bleu_fts = [bleu_prec(s1,s2),bleu_rec(s1,s2),\n\u001b[1;32m      6\u001b[0m                 bleu_prec(s1,s2,lemmatized=True),bleu_rec(s1,s2,lemmatized=True)]\n",
      "\u001b[0;32m<ipython-input-43-8fc2022318c7>\u001b[0m in \u001b[0;36muni_prec\u001b[0;34m(s1, s2, lemmatized)\u001b[0m\n\u001b[1;32m      4\u001b[0m         \u001b[0ms1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ms2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlemmatize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlemmatize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m     return div(word_overlap(s1,s2) *                sum(idf(w) for w in intersection(s1,s2)),\n\u001b[0m\u001b[1;32m      7\u001b[0m                len(s1))\n",
      "\u001b[0;32m<ipython-input-43-8fc2022318c7>\u001b[0m in \u001b[0;36m<genexpr>\u001b[0;34m((w,))\u001b[0m\n\u001b[1;32m      4\u001b[0m         \u001b[0ms1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ms2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlemmatize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlemmatize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m     return div(word_overlap(s1,s2) *                sum(idf(w) for w in intersection(s1,s2)),\n\u001b[0m\u001b[1;32m      7\u001b[0m                len(s1))\n",
      "\u001b[0;32m<ipython-input-92-431980d535e9>\u001b[0m in \u001b[0;36midf\u001b[0;34m(w)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0midf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mw\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mlog\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdiv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mN\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mbrown_words\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcount\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mw\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-91-38c2ca800ec7>\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m(x)\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mlog\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlog\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m>\u001b[0m\u001b[0;36m0\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m     \u001b[0;31m# intuitively N > word_count(w) for any w,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0;31m#  therefore we cannot let idf(w) be negative\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0;31m#  even when word_count(w) = 0 for w.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mdiv\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0my\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m!=\u001b[0m\u001b[0;36m0\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "%%time\n",
    "X_train_fts, Y_train_fts = featurize_set(X_train, Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "X_test_fts, Y_test_fts = featurize_set(X_test, Y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# TODO: long ass sentence issue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 466,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "defaultdict(list,\n",
       "            {'s1': [u'A',\n",
       "              u'BMI',\n",
       "              u'of',\n",
       "              u'25',\n",
       "              u'or',\n",
       "              u'above',\n",
       "              u'is',\n",
       "              u'considered',\n",
       "              u'overweight',\n",
       "              u';',\n",
       "              u'30',\n",
       "              u'or',\n",
       "              u'above',\n",
       "              u'is',\n",
       "              u'considered',\n",
       "              u'obese',\n",
       "              u'.'],\n",
       "             's1_id': 1713015,\n",
       "             's2': [u'A',\n",
       "              u'BMI',\n",
       "              u'between',\n",
       "              u'18.5',\n",
       "              u'and',\n",
       "              u'24.9',\n",
       "              u'is',\n",
       "              u'considered',\n",
       "              u'normal',\n",
       "              u',',\n",
       "              u'over',\n",
       "              u'25',\n",
       "              u'is',\n",
       "              u'considered',\n",
       "              u'overweight',\n",
       "              u'and',\n",
       "              u'30',\n",
       "              u'or',\n",
       "              u'greater',\n",
       "              u'is',\n",
       "              u'defined',\n",
       "              u'as',\n",
       "              u'obese',\n",
       "              u'.'],\n",
       "             's2_id': 1712982})"
      ]
     },
     "execution_count": 466,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train[24]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 467,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "s241 = X_train[24]['s1']\n",
    "s242 = X_train[24]['s2']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 468,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "21"
      ]
     },
     "execution_count": 468,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tree_edit_dist(s241,s242)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import cPickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data_path = \"/Users/jacobsw/Desktop/WORK/OJO_CODE/SENTENCE_SIMILARITIES/DATA/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open(data_path+'train.p','wb') as f_train:\n",
    "    cPickle.dump((X_train_fts,Y_train_fts), f_train)\n",
    "with open(data_path+'test.p','wb') as f_test:\n",
    "    cPickle.dump((X_test_fts,Y_test_fts), f_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 437,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "t_X, t_Y = [X_train[i] for i in range(5)], [Y_train[i] for i in range(5)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 440,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 15.1 s, sys: 37.6 ms, total: 15.1 s\n",
      "Wall time: 15.2 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "t_Xlist, t_Ylist = featurize_set(t_X,t_Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 441,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4076"
      ]
     },
     "execution_count": 441,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 442,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "815.2"
      ]
     },
     "execution_count": 442,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "4076/5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 443,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "12391.04"
      ]
     },
     "execution_count": 443,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "815.2*15.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 444,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "206.51733333333334"
      ]
     },
     "execution_count": 444,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "12391.04/60"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 446,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3.441955555555556"
      ]
     },
     "execution_count": 446,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "206.51733333333334/60 # time needed to featurize the entrie training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 447,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1725"
      ]
     },
     "execution_count": 447,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 449,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.4566666666666668"
      ]
     },
     "execution_count": 449,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "((1725/5)*15.2)/3600"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 450,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4.898622222222222"
      ]
     },
     "execution_count": 450,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "3.441955555555556 + 1.4566666666666668 # expected time for featurizing entire corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 423,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tx1 = featurize(s0,s1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 424,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 39.33302016,  37.14785237,  54.53171271,  51.50217312,\n",
       "         0.5856596 ,   0.57735027,   0.5856596 ,   0.57735027,\n",
       "         0.6       ,   0.52941176,   0.5625    ,   0.52941176,\n",
       "        38.20921958,   0.58147525,   0.5625    ,  52.97366378,\n",
       "         0.58147525,   0.54545455,  17.        ,  10.        ,\n",
       "        -1.        ,   1.        ])"
      ]
     },
     "execution_count": 424,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tx1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 425,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ty1 = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 426,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tx2 = featurize(s0,s2)\n",
    "ty2 = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 417,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 418,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "lr = LogisticRegression()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 427,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
       "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
       "          verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 427,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr.fit([tx1,tx2],[ty1,ty2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### B. Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### C. SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
