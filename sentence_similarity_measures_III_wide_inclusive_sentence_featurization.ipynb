{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Sentence Similarity Measures III: Wide-Inclusive Sentence Featurization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## 0. Contents\n",
    "\n",
    "* I. Corpora:\n",
    "    * MSR Paraphrase Corpus\n",
    "    * Brown\n",
    "* II. Discriminativity Weighting (Brown, SpaCy lemmatization)\n",
    "* III. Featurization:\n",
    "    * Features:\n",
    "        * Unigram Prec/Rec (Wan et al. 2006) \n",
    "        * Bleu Prec/Rec (Papineni et al. 2002)\n",
    "        * Dependency Prec/Rec (Wan et al. 2006; Moll$\\acute{a}$ 2003; Hovy et al. 2015)\n",
    "        * F1 for Unigram, Bleu & Dependency\n",
    "        * Tree Edit Distance (Zhang & Sasha Algorithm)\n",
    "        * Sentence Lengths (Wan et al. 2006)\n",
    "    * Featurization Function\n",
    "* IV. Paraphrase Classifier:\n",
    "    * Training: MSR Paraphrase Corpus\n",
    "    * Classifier Types:\n",
    "        * Logistic\n",
    "        * SVM\n",
    "* V. Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## I. Corpora"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from nltk.corpus import brown\n",
    "from spacy.en import English\n",
    "from collections import defaultdict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "parser = English()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Load MSR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_path = \"/Users/jacobsw/Desktop/WORK/OJO_CODE/SENTENCE_SIMILARITIES/CORPORA/paraphrase/msr_paraphrase_train.txt\"\n",
    "test_path = \"/Users/jacobsw/Desktop/WORK/OJO_CODE/SENTENCE_SIMILARITIES/CORPORA/paraphrase/msr_paraphrase_test.txt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>﻿Quality</th>\n",
       "      <th>#1 ID</th>\n",
       "      <th>#2 ID</th>\n",
       "      <th>#1 String</th>\n",
       "      <th>#2 String</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>702876</td>\n",
       "      <td>702977</td>\n",
       "      <td>Amrozi accused his brother, whom he called the...</td>\n",
       "      <td>Referring to him as only the witness, Amrozi a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>2108705</td>\n",
       "      <td>2108831</td>\n",
       "      <td>Yucaipa owned Dominick's before selling the ch...</td>\n",
       "      <td>Yucaipa bought Dominick's in 1995 for $693 mil...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>1330381</td>\n",
       "      <td>1330521</td>\n",
       "      <td>They had published an advertisement on the Int...</td>\n",
       "      <td>On June 10, the ship's owners had published an...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>3344667</td>\n",
       "      <td>3344648</td>\n",
       "      <td>Around 0335 GMT, Tab shares were up 19 cents, ...</td>\n",
       "      <td>Tab shares jumped 20 cents, or 4.6%, to set a ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>1236820</td>\n",
       "      <td>1236712</td>\n",
       "      <td>The stock rose $2.11, or about 11 percent, to ...</td>\n",
       "      <td>PG&amp;E Corp. shares jumped $1.63 or 8 percent to...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   ﻿Quality    #1 ID    #2 ID  \\\n",
       "0         1   702876   702977   \n",
       "1         0  2108705  2108831   \n",
       "2         1  1330381  1330521   \n",
       "3         0  3344667  3344648   \n",
       "4         1  1236820  1236712   \n",
       "\n",
       "                                           #1 String  \\\n",
       "0  Amrozi accused his brother, whom he called the...   \n",
       "1  Yucaipa owned Dominick's before selling the ch...   \n",
       "2  They had published an advertisement on the Int...   \n",
       "3  Around 0335 GMT, Tab shares were up 19 cents, ...   \n",
       "4  The stock rose $2.11, or about 11 percent, to ...   \n",
       "\n",
       "                                           #2 String  \n",
       "0  Referring to him as only the witness, Amrozi a...  \n",
       "1  Yucaipa bought Dominick's in 1995 for $693 mil...  \n",
       "2  On June 10, the ship's owners had published an...  \n",
       "3  Tab shares jumped 20 cents, or 4.6%, to set a ...  \n",
       "4  PG&E Corp. shares jumped $1.63 or 8 percent to...  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train = pd.read_csv(train_path, delimiter='\\t')\n",
    "df_test = pd.read_csv(test_path, delimiter='\\t')\n",
    "df_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4076, 5)\n",
      "(1725, 5)\n"
     ]
    }
   ],
   "source": [
    "print df_train.shape\n",
    "print df_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "﻿Quality                                                     1\n",
       "#1 ID                                                   702876\n",
       "#2 ID                                                   702977\n",
       "#1 String    Amrozi accused his brother, whom he called the...\n",
       "#2 String    Referring to him as only the witness, Amrozi a...\n",
       "Name: 0, dtype: object"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.ix[0] # NB: index Quality is actually weirdly '﻿Quality'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Amrozi accused his brother, whom he called the witness, of deliberately distorting his evidence.'"
      ]
     },
     "execution_count": 172,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.ix[0]['#1 String']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Make Train/Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dep_lemmas = lambda parsed_s: {(token.head.lemma_,token.lemma_) for token in parsed_s\n",
    "                             if token.head.lemma_!=token.lemma_} # eliminte (v, ROOT, v) cases\n",
    "dep_tokens = lambda parsed_s: {(token.head.orth_,token.orth_) for token in parsed_s\n",
    "                             if token.head.lemma_!=token.lemma_}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "get_root = lambda parsed_s: [token for token in parsed_s if token.lemma_==token.head.lemma_][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def parse_msr(df, indexer):\n",
    "    \n",
    "    X_dic, Y_dic = defaultdict(lambda x: defaultdict(list)), \\\n",
    "                   defaultdict(lambda x: defaultdict(list))\n",
    "    \n",
    "    for i in indexer:\n",
    "        entry_dic = defaultdict(list)\n",
    "        s1, s2 = df.ix[i]['#1 String'].decode('utf-8','ignore')[:-1], \\\n",
    "                 df.ix[i]['#2 String'].decode('utf-8','ignore')[:-1] \n",
    "                # get rid of period, which causes problem in distinguishing identical tokens.\n",
    "        \n",
    "        parsed_s1, parsed_s2 = parser(unicode(s1)), parser(unicode(s2))\n",
    "        entry_dic['s1'] = [token.orth_ for token in parsed_s1]\n",
    "        entry_dic['s2'] = [token.orth_ for token in parsed_s2]\n",
    "        entry_dic['s1_lm'] = [token.lemma_ for token in parsed_s1]\n",
    "        entry_dic['s2_lm'] = [token.lemma_ for token in parsed_s2]\n",
    "        entry_dic['s1_dep_lm'] = dep_lemmas(parsed_s1) # for dep lemma features.\n",
    "        entry_dic['s2_dep_lm'] = dep_lemmas(parsed_s2)\n",
    "        entry_dic['s1_dep_tk'] = dep_tokens(parsed_s1) # for dep token features.\n",
    "        entry_dic['s2_dep_tk'] = dep_tokens(parsed_s2)  \n",
    "        entry_dic['s1_root'] = get_root(parsed_s1)\n",
    "        entry_dic['s2_root'] = get_root(parsed_s2)\n",
    "        entry_dic['s1_id'] = df.ix[i]['#1 ID'] # for error analysis later.\n",
    "        entry_dic['s2_id'] = df.ix[i]['#2 ID']\n",
    "        X_dic[i] = entry_dic\n",
    "        Y_dic[i] = df.ix[i]['﻿Quality']\n",
    "    \n",
    "    return X_dic, Y_dic\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 14.9 s, sys: 65.3 ms, total: 15 s\n",
      "Wall time: 15 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "X_train, Y_train = parse_msr(df_train, df_train.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 6.59 s, sys: 17.5 ms, total: 6.61 s\n",
      "Wall time: 6.62 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "X_test, Y_test = parse_msr(df_test, df_test.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sentence 1:  [u'Amrozi', u'accused', u'his', u'brother', u',', u'whom', u'he', u'called', u'the', u'witness', u',', u'of', u'deliberately', u'distorting', u'his', u'evidence']\n",
      "\n",
      "sentence 2:  [u'Referring', u'to', u'him', u'as', u'only', u'the', u'witness', u',', u'Amrozi', u'accused', u'his', u'brother', u'of', u'deliberately', u'distorting', u'his', u'evidence']\n",
      "\n",
      "paraphrase label:  1\n"
     ]
    }
   ],
   "source": [
    "print 'sentence 1: ', X_train[0]['s1']; print\n",
    "print 'sentence 2: ', X_train[0]['s2']; print\n",
    "print 'paraphrase label: ', Y_train[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Load Brown"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def parse_brown():\n",
    "    \n",
    "    sents = brown.sents()\n",
    "    parsed_sents = [parser(' '.join(sent)) for sent in sents]\n",
    "    lemma_words = [token.lemma_ for parsed_sent in parsed_sents for token in parsed_sent]\n",
    "    \n",
    "    return lemma_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1min 25s, sys: 469 ms, total: 1min 25s\n",
      "Wall time: 1min 25s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "brown_words = parse_brown()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1188973"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "N = len(brown_words)\n",
    "N"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## I. Discriminativity Weighting (IDF)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Math**\n",
    "\n",
    "* $IDF(w) = log\\frac{N}{df_w}$, where $N$ is the number of words in a corpus; $df_w$ is word $w$'s frequency in the corpus."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from __future__ import division"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "log = lambda x: np.log(x) if x>0 else 0 \n",
    "    # intuitively N > word_count(w) for any w,\n",
    "    #  therefore we cannot let idf(w) be negative\n",
    "    #  even when word_count(w) = 0 for w.\n",
    "div = lambda x,y: x/y if y!=0 else 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def idf(w):\n",
    "    \n",
    "    return log(div(N,brown_words.count(w)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'the':  2.83230709\n",
      "'discriminate':  12.0426903182\n"
     ]
    }
   ],
   "source": [
    "print \"'the': \", idf('the')\n",
    "print \"'discriminate': \", idf('discriminate')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## IIa. Features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### A.  Unigram Prec/Rec"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Math**\n",
    "\n",
    "* $Uni\\_Prec(s_1,s_2) = \\frac{word\\_overlap(s_1,s_2)\\cdot \\left(\\sum_{w\\in s_1\\cap s_2}log\\frac{N}{df_w}\\right)}{word\\_count(s_1)}$ (cf. Wan et al. 2006:133, weighted by $IDF$)\n",
    "\n",
    "\n",
    "* $Uni\\_Rec(s_1,s_2) = \\frac{word\\_overlap(s_1,s_2)\\cdot \\left(\\sum_{w\\in s_1\\cap s_2}log\\frac{N}{df_w}\\right)}{word\\_count(s_2)}$ (cf. ibid.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "intersection = lambda s1,s2: set(s1).intersection(set(s2))\n",
    "word_overlap = lambda s1,s2: len(intersection(s1,s2))\n",
    "lemmatize = lambda s: [token.lemma_ for token in parser(' '.join(s))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def uni_prec(s1, s2): # s1,s2 assumed to be lists of words (lemmas or tokens)\n",
    "\n",
    "    return div(word_overlap(s1,s2) * \\\n",
    "               sum(idf(w) for w in intersection(s1,s2)),\n",
    "               len(s1))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def uni_rec(s1, s2):   \n",
    "    \n",
    "    return div(word_overlap(s1,s2) * \\\n",
    "               sum(idf(w) for w in intersection(s1,s2)),\n",
    "               len(s2))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "s0 = X_train[0]['s1']\n",
    "s1 = X_train[0]['s2'] # known to be the paraphrase of q\n",
    "s2 = X_train[1]['s1'] # known to not be the paraphrase of q\n",
    "s0_lm = X_train[0]['s1_lm']\n",
    "s1_lm = X_train[0]['s2_lm']\n",
    "s2_lm = X_train[1]['s1_lm']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "36.1294834287\n",
      "0.177019193125\n",
      "50.9323766953\n",
      "0.177019193125\n",
      "CPU times: user 620 ms, sys: 1.21 ms, total: 622 ms\n",
      "Wall time: 622 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "print uni_prec(s0,s1)\n",
    "print uni_prec(s0,s2)\n",
    "print uni_prec(s0_lm,s1_lm)\n",
    "print uni_prec(s0_lm,s2_lm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "34.0042196976\n",
      "0.177019193125\n",
      "47.9363545368\n",
      "0.177019193125\n",
      "CPU times: user 632 ms, sys: 1.13 ms, total: 634 ms\n",
      "Wall time: 634 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "print uni_rec(s0,s1)\n",
    "print uni_rec(s0,s2)\n",
    "print uni_rec(s0_lm,s1_lm)\n",
    "print uni_rec(s0_lm,s2_lm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### B. BLEU Prec/Rec"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**NB** (cf. Wan et al. 2006:133)\n",
    "\n",
    "* \"... Bleu metric uses the geometric average of unigram, bigram and trigram precision scores.\"\n",
    "* \"... by reversing [two sentences], ... a recall version of Bleu is obtained.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from nltk import bleu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def bleu_prec(s1, s2, lemmatized=False): # s1 as the 'hypothesis'\n",
    "\n",
    "    return bleu(s2,s1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def bleu_rec(s1, s2, lemmatized=False): # s2 as the 'hypothesis' \n",
    "    \n",
    "    return bleu(s1,s2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5\n",
      "0\n",
      "0.5\n",
      "0\n",
      "CPU times: user 7.14 ms, sys: 2.93 ms, total: 10.1 ms\n",
      "Wall time: 7.61 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "print bleu_prec(s0,s1)\n",
    "print bleu_prec(s0,s2)\n",
    "print bleu_prec(s0_lm,s1_lm)\n",
    "print bleu_prec(s0_lm,s2_lm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.492479060505\n",
      "0\n",
      "0.492479060505\n",
      "0\n",
      "CPU times: user 6.58 ms, sys: 2.44 ms, total: 9.01 ms\n",
      "Wall time: 7.4 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "print bleu_rec(s0,s1)\n",
    "print bleu_rec(s0,s2)\n",
    "print bleu_rec(s0_lm,s1_lm)\n",
    "print bleu_rec(s0_lm,s2_lm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### C. Dependency Prec/Rec"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Math**\n",
    "\n",
    "* $Dep\\_Prec(s_1,s_2) = \\frac{|dep\\_pair(s_1)|\\cap|dep\\_pair(s_2)|}{|dep\\_pair(s_1)|}$ (cf. Wan et al. 2006:134)\n",
    "\n",
    "\n",
    "* $Dep\\_Rec(s_1,s_2) = \\frac{|dep\\_pair(s_1)|\\cap|dep\\_pair(s_2)|}{|dep\\_pair(s_2)|}$ (cf. ibid.)\n",
    "\n",
    "**NB**: $relation$ in the reference confuses *dependency pair* with *dependency relation*. $relation$ refers to \"... a pair of words in a parent-child relationship within the dependency tree, referred to as head-modifier relationship. ... we ignore the label of the relationships which indicates the semantic role\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def dep_prec(dep_pairs_s1, dep_pairs_s2):\n",
    "    \n",
    "    return div(len(dep_pairs_s1.intersection(dep_pairs_s2)),\n",
    "               len(dep_pairs_s1))\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def dep_rec(dep_pairs_s1, dep_pairs_s2):\n",
    "    \n",
    "    return div(len(dep_pairs_s1.intersection(dep_pairs_s2)),\n",
    "               len(dep_pairs_s2))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "s0_dep_tk = X_train[0]['s1_dep_tk']\n",
    "s1_dep_tk = X_train[0]['s2_dep_tk']\n",
    "s2_dep_tk = X_train[1]['s1_dep_tk']\n",
    "s0_dep_lm = X_train[0]['s1_dep_lm']\n",
    "s1_dep_lm = X_train[0]['s2_dep_lm']\n",
    "s2_dep_lm = X_train[1]['s1_dep_lm']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.571428571429\n",
      "0.0\n",
      "0.571428571429\n",
      "0.0\n",
      "CPU times: user 278 µs, sys: 125 µs, total: 403 µs\n",
      "Wall time: 287 µs\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "print dep_prec(s0_dep_tk,s1_dep_tk)\n",
    "print dep_prec(s0_dep_tk,s2_dep_tk)\n",
    "print dep_prec(s0_dep_lm,s1_dep_lm)\n",
    "print dep_prec(s0_dep_lm,s2_dep_lm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.571428571429\n",
      "0.0\n",
      "0.571428571429\n",
      "0.0\n",
      "CPU times: user 419 µs, sys: 348 µs, total: 767 µs\n",
      "Wall time: 496 µs\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "print dep_prec(s0_dep_tk,s1_dep_tk)\n",
    "print dep_prec(s0_dep_tk,s2_dep_tk)\n",
    "print dep_prec(s0_dep_lm,s1_dep_lm)\n",
    "print dep_prec(s0_dep_lm,s2_dep_lm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### D. F1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Math**\n",
    "\n",
    "* $F1 = 2\\cdot\\frac{prec\\cdot rec}{prec + rec}$ (cf. https://en.wikipedia.org/wiki/F1_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def f1_unigram(s1, s2):\n",
    "    \n",
    "    prec, rec = uni_prec(s1,s2), uni_rec(s1,s2)\n",
    "    \n",
    "    return prec, rec, 2*div(prec*rec,prec+rec) # so later we only do uni_prec/rec once!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def f1_bleu(s1, s2):\n",
    "    \n",
    "    prec, rec = bleu_prec(s1,s2), bleu_rec(s1,s2)\n",
    "    \n",
    "    return prec, rec, 2*div(prec*rec,prec+rec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def f1_dep(dep_pairs_s1, dep_pairs_s2):\n",
    "   \n",
    "    prec, rec = dep_prec(dep_pairs_s1,dep_pairs_s2), \\\n",
    "                dep_rec(dep_pairs_s1,dep_pairs_s2)\n",
    "    \n",
    "    return prec, rec, 2*div(prec*rec,prec+rec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "35.0346505975\n",
      "0.177019193125\n",
      "49.3889713409\n",
      "0.177019193125\n",
      "CPU times: user 1.3 s, sys: 2.82 ms, total: 1.3 s\n",
      "Wall time: 1.31 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "print f1_unigram(s0,s1)[2]\n",
    "print f1_unigram(s0,s2)[2]\n",
    "print f1_unigram(s0_lm,s1_lm)[2]\n",
    "print f1_unigram(s0_lm,s2_lm)[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.496211033666\n",
      "0\n",
      "0.496211033666\n",
      "0\n",
      "CPU times: user 13.9 ms, sys: 4.99 ms, total: 18.9 ms\n",
      "Wall time: 15.1 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "print f1_bleu(s0,s1)[2]\n",
    "print f1_bleu(s0,s2)[2]\n",
    "print f1_bleu(s0_lm,s1_lm)[2]\n",
    "print f1_bleu(s0_lm,s2_lm)[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.533333333333\n",
      "0\n",
      "0.533333333333\n",
      "0\n",
      "CPU times: user 219 µs, sys: 134 µs, total: 353 µs\n",
      "Wall time: 260 µs\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "print f1_dep(s0_dep_tk,s1_dep_tk)[2]\n",
    "print f1_dep(s0_dep_tk,s2_dep_tk)[2]\n",
    "print f1_dep(s0_dep_lm,s1_dep_lm)[2]\n",
    "print f1_dep(s0_dep_lm,s2_dep_lm)[2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### E. Tree Edit Distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from zss import simple_distance, Node\n",
    "    # use zss.distance if dynamic tree modification is needed. \n",
    "    #  cf. zss api: pythonhosted.org/zss/."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def make_tree(token, lemmatized):\n",
    "    \n",
    "    node = Node(token.lemma_) if lemmatized else Node(token.orth_)\n",
    "    children = get_children(token)\n",
    "    if len(children)==0: return node\n",
    "    for child in children:\n",
    "        node.addkid(make_tree(child, lemmatized))\n",
    "    \n",
    "    return node\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def tree_edit_dist(root_s1, root_s2, lemmatized=False):\n",
    "    \n",
    "    return simple_distance(make_tree(root_s1, lemmatized),\n",
    "                           make_tree(root_s2, lemmatized))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "s0_root = X_train[0]['s1_root']\n",
    "s1_root = X_train[0]['s2_root']\n",
    "s2_root = X_train[1]['s1_root']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13\n",
      "21\n",
      "CPU times: user 18.2 ms, sys: 8.67 ms, total: 26.9 ms\n",
      "Wall time: 20 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "print tree_edit_dist(s0_root,s1_root)\n",
    "print tree_edit_dist(s0_root,s2_root)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13\n",
      "21\n",
      "CPU times: user 17.1 ms, sys: 7.2 ms, total: 24.3 ms\n",
      "Wall time: 18.9 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "print tree_edit_dist(s0_root,s1_root,lemmatized=True)\n",
    "print tree_edit_dist(s0_root,s2_root,lemmatized=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### F. Sentence Lengths"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* \"... the difference in length of two sentences ... measured in words by subtracting one length from the other.\" (cf. Wan et al. 2006:134)\n",
    "* \"... this difference could be a negative or positive integer ... an absolute variant was used.\" (cf. ibid.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def sent_len_diffs(s1, s2):\n",
    "    \n",
    "    diff = len(s1)-len(s2)\n",
    "    \n",
    "    return [diff, abs(diff)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-1, 1]\n",
      "[0, 0]\n"
     ]
    }
   ],
   "source": [
    "print sent_len_diffs(s0,s1)\n",
    "print sent_len_diffs(s0,s2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## IIb: Featurization Function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Features (22 in total)**:\n",
    "\n",
    "* Unigram Prec/Rec + lemmatized variant: 4\n",
    "* Bleu Prec/Rec + lemmatized variant: 4\n",
    "* Dependency Prec/Rec + lemmatized variant: 4\n",
    "* F1 Unigram, Bleu, Dependency + lemmatized variant: 6\n",
    "* Tree Edit Distance + lemmatized variant: 2\n",
    "* Sentence Lengths: 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def featurize_new(s1, s2): \n",
    "    # featurize a new input.\n",
    "    # s is a list of words.\n",
    "\n",
    "    parsed_s1, parsed_s2 = parser(s1), parser(s2)\n",
    "    s1_lm = [token.lemma_ for token in parsed_s1]\n",
    "    s2_lm = [token.lemma_ for token in parsed_s2]\n",
    "    s1_dep_lm, s2_dep_lm = dep_lemmas(parsed_s1), dep_lemmas(parsed_s2)\n",
    "    s1_dep_tk, s2_dep_tk = dep_tokens(parsed_s1), dep_tokens(parsed_s2)\n",
    "    s1_root, s2_root = get_root(parsed_s1), get_root(parsed_s2)\n",
    "    \n",
    "    uni_tk_prec, uni_tk_rec, uni_tk_f1 = f1_unigram(s1, s2)\n",
    "    uni_lm_prec, uni_lm_rec, uni_lm_f1 = f1_unigram(s1_lm, s2_lm)\n",
    "    bleu_tk_prec, bleu_tk_rec, bleu_tk_f1 = f1_bleu(s1, s2)\n",
    "    bleu_lm_prec, bleu_lm_rec, bleu_lm_f1 = f1_bleu(s1_lm, s2_lm)\n",
    "    dep_tk_prec, dep_tk_rec, dep_tk_f1 = f1_dep(s1_dep_tk, s2_dep_tk)\n",
    "    dep_lm_prec, dep_lm_rec, dep_lm_f1 = f1_dep(s1_dep_lm, s2_dep_lm)\n",
    "    tree_tk_dist = tree_edit_dist(s1_root, s2_root)\n",
    "    tree_lm_dist = tree_edit_dist(s1_root, s2_root, lemmatized=True)\n",
    "    diff, abs_diff = sent_len_diffs(s1, s2)\n",
    "\n",
    "    return [uni_tk_prec, uni_tk_rec, uni_tk_f1,\n",
    "            uni_lm_prec, uni_lm_rec, uni_lm_f1,\n",
    "            bleu_tk_prec, bleu_tk_rec, bleu_tk_f1,\n",
    "            bleu_lm_prec, bleu_lm_rec, bleu_lm_f1,\n",
    "            dep_tk_prec, dep_tk_rec, dep_tk_f1,\n",
    "            dep_lm_prec, dep_lm_rec, dep_lm_f1,\n",
    "            tree_tk_dist, tree_lm_dist,\n",
    "            diff, abs_diff]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 259,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Amrozi accused his brother , whom he called the witness , of deliberately distorting his evidence\n",
      "Referring to him as only the witness , Amrozi accused his brother of deliberately distorting his evidence\n",
      "Yucaipa owned Dominick 's before selling the chain to Safeway in 1998 for $ 2.5 billion\n"
     ]
    }
   ],
   "source": [
    "s0_asnew, s1_asnew, s2_asnew = ' '.join(s0), ' '.join(s1), ' '.join(s2)\n",
    "print s0_asnew\n",
    "print s1_asnew\n",
    "print s2_asnew"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 261,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[52.231568075980661, 48.252020032096418, 50.162991122476484, 50.932376695342796, 47.936354536793218, 49.388971340938468, 0.7052772528401912, 0.691441569283882, 0.6982908839768287, 0.5, 0.4924790605054523, 0.49621103366618263, 0.5714285714285714, 0.5, 0.5333333333333333, 0.5714285714285714, 0.5, 0.5333333333333333, 13, 13, -8, 8]\n",
      "\n",
      "[38.373129966155794, 42.783834559966806, 40.45862615996861, 0.17701919312505979, 0.17701919312505979, 0.17701919312505976, 0.6738520677318575, 0.6924328859069189, 0.6830161317245619, 0, 0, 0, 0.0, 0.0, 0, 0.0, 0.0, 0, 21, 21, 10, 10]\n"
     ]
    }
   ],
   "source": [
    "print featurize_new(s0_asnew,s1_asnew)\n",
    "print \n",
    "print featurize_new(s0_asnew,s2_asnew)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## IV. Paraphrase Classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### A. Featurizing Training/Test from MSR\n",
    "\n",
    "* \"... the training set contains 2753 true paraphrase pairs and 1323 false paraphrase pairs; ... the test set contains 1147 and 578 pairs, respectively.\" (cf. Ji & Eisenstein 2013:893)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['s1_dep_lm', 's1_lm', 's2_dep_lm', 's2', 's1', 's2_root', 's1_dep_tk', 's1_root', 's1_id', 's2_dep_tk', 's2_id', 's2_lm']\n"
     ]
    }
   ],
   "source": [
    "print X_train[0].keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def featurize_set(X, Y):\n",
    "    \n",
    "    X_list, Y_list = [], []\n",
    "    \n",
    "    for i in xrange(len(X)):\n",
    "\n",
    "        uni_tk_prec, uni_tk_rec, uni_tk_f1 = f1_unigram(X[i]['s1'], X[i]['s2'])\n",
    "        uni_lm_prec, uni_lm_rec, uni_lm_f1 = f1_unigram(X[i]['s1_lm'], X[i]['s2_lm'])\n",
    "        bleu_tk_prec, bleu_tk_rec, bleu_tk_f1 = f1_bleu(X[i]['s1'], X[i]['s2'])\n",
    "        bleu_lm_prec, bleu_lm_rec, bleu_lm_f1 = f1_bleu(X[i]['s1_lm'], X[i]['s2_lm'])\n",
    "        dep_tk_prec, dep_tk_rec, dep_tk_f1 = f1_dep(X[i]['s1_dep_tk'], X[i]['s2_dep_tk'])\n",
    "        dep_lm_prec, dep_lm_rec, dep_lm_f1 = f1_dep(X[i]['s1_dep_lm'], X[i]['s2_dep_lm'])\n",
    "        tree_tk_dist = tree_edit_dist(X[i]['s1_root'], X[i]['s2_root'])\n",
    "        tree_lm_dist = tree_edit_dist(X[i]['s1_root'], X[i]['s2_root'],lemmatized=True) \n",
    "        diff, abs_diff = sent_len_diffs(X[i]['s1'], X[i]['s2'])\n",
    "        X_list.append(\n",
    "            [uni_tk_prec, uni_tk_rec, uni_tk_f1,\n",
    "             uni_lm_prec, uni_lm_rec, uni_lm_f1,\n",
    "             bleu_tk_prec, bleu_tk_rec, bleu_tk_f1,\n",
    "             bleu_lm_prec, bleu_lm_rec, bleu_lm_f1,\n",
    "             dep_tk_prec, dep_tk_rec, dep_tk_f1,\n",
    "             dep_lm_prec, dep_lm_rec, dep_lm_f1,\n",
    "             tree_tk_dist, tree_lm_dist,\n",
    "            diff, abs_diff]\n",
    "        )\n",
    "        Y_list.append(Y[i])\n",
    "    \n",
    "    return X_list, Y_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 268,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1h 55min 21s, sys: 35 s, total: 1h 55min 56s\n",
      "Wall time: 1h 56min 57s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "X_train_fts, Y_train_fts = featurize_set(X_train, Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 269,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 38min 25s, sys: 5.13 s, total: 38min 30s\n",
      "Wall time: 38min 30s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "X_test_fts, Y_test_fts = featurize_set(X_test, Y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 270,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import cPickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 271,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data_path = \"/Users/jacobsw/Desktop/WORK/OJO_CODE/SENTENCE_SIMILARITIES/DATA/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 272,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# with open(data_path+'train.p','wb') as f_train:\n",
    "#     cPickle.dump((X_train_fts,Y_train_fts), f_train)\n",
    "# with open(data_path+'test.p','wb') as f_test:\n",
    "#     cPickle.dump((X_test_fts,Y_test_fts), f_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 286,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[36.129483428692055, 34.004219697592525, 35.034650597519565, 50.932376695342796, 47.936354536793218, 49.388971340938468, 0.5, 0.4924790605054523, 0.49621103366618263, 0.5, 0.4924790605054523, 0.49621103366618263, 0.5714285714285714, 0.5, 0.5333333333333333, 0.5714285714285714, 0.5, 0.5333333333333333, 13, 13, -1, 1]\n"
     ]
    }
   ],
   "source": [
    "print X_train_fts[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### B. Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 282,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 275,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "lr = LogisticRegression()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 276,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
       "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
       "          verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 276,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr.fit(X_train_fts, Y_train_fts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 277,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y_true = Y_test_fts\n",
    "y_pred = lr.predict(X_test_fts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 285,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "73.3913043478\n"
     ]
    }
   ],
   "source": [
    "print (accuracy_score(y_true,y_pred)*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 284,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.63      0.51      0.56       578\n",
      "          1       0.77      0.85      0.81      1147\n",
      "\n",
      "avg / total       0.72      0.73      0.73      1725\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print classification_report(y_true,y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# TODO: top5 accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 297,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1])"
      ]
     },
     "execution_count": 297,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr.predict([X_test_fts[0]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 298,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.43530027,  0.56469973]])"
      ]
     },
     "execution_count": 298,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr.predict_proba([X_test_fts[0]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### C. SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 287,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn import svm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 300,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "clf = svm.SVC(probability=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 301,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVC(C=1.0, cache_size=200, class_weight=None, coef0=0.0,\n",
       "  decision_function_shape=None, degree=3, gamma='auto', kernel='rbf',\n",
       "  max_iter=-1, probability=True, random_state=None, shrinking=True,\n",
       "  tol=0.001, verbose=False)"
      ]
     },
     "execution_count": 301,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.fit(X_train_fts, Y_train_fts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 302,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y_true = Y_test_fts\n",
    "y_pred = clf.predict(X_test_fts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 303,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "69.1594202899\n"
     ]
    }
   ],
   "source": [
    "print (accuracy_score(y_true,y_pred)*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 304,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.58      0.29      0.39       578\n",
      "          1       0.71      0.89      0.79      1147\n",
      "\n",
      "avg / total       0.67      0.69      0.66      1725\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print classification_report(y_true,y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# TODO: top5 accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 306,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1])"
      ]
     },
     "execution_count": 306,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.predict([X_test_fts[0]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 307,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.28224807,  0.71775193]])"
      ]
     },
     "execution_count": 307,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.predict_proba([X_test_fts[0]])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
